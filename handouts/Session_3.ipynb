{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Session 3: Concepticon (Johann-Mattis List and Tiago Tresoldi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1 Reference Catalogs\n",
    "\n",
    "While we often think of linguistic data in terms of a datapoint tied to a specific language variety or a specific language family, many aspects of linguistic data can be generalized. The most prominentt example would be language names, as the the names which scholars give to the language varieties they study may often vary (for different reasons, be it socio-cultural, traditions of specific scholarly fields, etc.), and these issues are differently addressed and may vary from study to study and dataset to dataset. Given that the first and foremost goal of computer-assisted approaches to historical language comparison is to make sure that data *is* comparable across applications, it is important to have some kind of authority that can be used in order to reference a given language variety. Since most linguists are anarchists deep down in their hearts, it is easy to understand that following some authority when writing papers or creating datasets where they include data of different language varieties, is not the first thing they think of when creating and curating cross-linguistic data. If a certain name is common for the variety they work on in their specific field of study, but the authorities give it another name which follows other fields, it is obvious that they don't want to use the name that most scholars use but rather the name that is most appropriate for their peers. \n",
    "\n",
    "This is where reference catalogs for language varieties come into play. A reference catalog of language names, geolocations, and expert classifications like the one offert by the [Glottolog](http://glottolog.org) project offers (a) unique identifiers for language names, (b) a release and update strategy to cope with errors in the data, or its expansion, and (c) exhaustive metadata (like references, classifications, etc.) linked to each of the unique identifiers. While scholars don't need to change the actual names they use to denote their language varieties in their work, all they need to do is to provide a mapping of the names they use and the identifiers provided by Glottolog in order to render their data comparable. But in contrast to what some scholars think, mapping language names in a given dataset to Glottolog does not result in unidirectional profit (from the scholar to the community), but instead enables those scholars who link their data to a reference catalog like Glottolog abundant amounts of metadata (references, classifications, geolocations), which they won't need to assemble themselves, since they are already there.\n",
    "\n",
    "This means, if scholars link their data to reference catalogs like Glottolog, both the community will profit, as scholars can easily find out which studies were devoted to which language varieties, while scholars who want to assemble linguistic data (mostly typologists and historical linguistics) can profit from the ground work on assigning metadata to languages that has been already done by the Glottolog editorial board.\n",
    "\n",
    "The idea of reference catalogs can be further expanded to other kinds of linguistic data. Concepts for example, are notoriously difficult to define, and yet scholars usually try to define them, as a lot of research is based on questionnaires where scholars assemble a list of concepts in some elicitation language and then go out to the field to ask their informations how they pronounce those concepts. Since questionnaires differ a lot, not only regarding the languages used for elicitation, but also regarding the specific conventions that scholars use to avoid the fuzziness of words in the eliciation language (e.g., distinction between noun and verb in words like *hand*), a catalog of concepts can help to render different studies comparable which are devoted to lexical data.\n",
    "\n",
    "Another example are phonetic transcriptions: Scholars often use different transcription systems, at times even customized variants, for several reasons like ease of typing, phonological considerations, or traditions in their field, but even if scholars use a system like the one proposed by the International Phonetic Alphabet, they may use it in slightly different ways. As a result, phonetic transcriptions are not necessarily directly comparable across datasets and studies. A reference catalog in which scholars provide their original transcriptions in a standardized form would again increase the comparability across datasets, but it would also be helpful for the scholars, as they could use such a reference catalog to receive information on additional aspects of sounds, such as common feature systems, general frequency distributions, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2 Background on Concept Lists\n",
    "\n",
    "In [1950](:bib:Swadesh1950), Morris Swadesh (1909 – 1967) proposed the idea that certain parts of the lexicon of human languages are universal, stable over time, and rather resistant to borrowing. As a result, he claimed that this part of the lexicon, which was later called basic vocabulary, would be very useful to address the problem of subgrouping in historical linguistics:\n",
    "\n",
    "> [...] it is a well known fact that certain types of\n",
    "> morphemes are relatively stable. Pronouns and\n",
    "> numerals, for example, are occasionally replaced\n",
    "> either by other forms from the same language or\n",
    "> by borrowed elements, but such replacement is\n",
    "> rare. The same is more or less true of other everyday expressions connected with concepts and\n",
    "> experiences common to all human groups or to\n",
    "> the groups living in a given part of the world during a given epoch. (Swadesh, 1950, 157)\n",
    "\n",
    "He illustrated this by proposing a first list of basic concepts,\n",
    "which was, in fact, nothing else than a collection of concept\n",
    "labels, as shown below:\n",
    "\n",
    "> I, thou, he, we, ye, one, two, three, four, five,\n",
    "> six, seven, eight, nine, ten, hundred, all, ani-\n",
    "> mal, ashes, back, bad, bark, belly, big, [...] this,\n",
    "> tongue, tooth, tree, warm, water, what, where,\n",
    "> white, who, wife, wind, woman, year, yellow.\n",
    "> (Swadesh, 1950, 161)\n",
    "\n",
    "In the following years, Swadesh refined his original concept\n",
    "lists of basic vocabulary items, thereby reducing the original test list of 215 items first to 200 ([Swadesh, 1952](:bib:Swadesh1952)) and\n",
    "then to 100 items ([Swadesh, 1955](:bib:Swadesh1955)). Scholars working on\n",
    "different language families and different datasets provided\n",
    "further modifications, be it that the concepts which Swadesh\n",
    "had proposed were lacking proper translational equivalents\n",
    "in the languages they were working on, or that they turned\n",
    "out to be not as stable and universal as Swadesh had claimed\n",
    "([Matisoff, 1978](:bib:Matisoff1978); [Alpher and Nash, 1999](:bib:Alpher1999)). Up to today,\n",
    "dozens of different concept lists have been compiled for var-\n",
    "ious purposes. They are used as heuristical tools for the de-\n",
    "tection of deep genetic relationships among languages ([Dolgopolsky, 1964](:bib:Dolgopolsky1964)), as basic values for traditional lexicostatistical and glottochronological studies \n",
    "([Dyen et al., 1992](:bib:Dyen1992);\n",
    "[Starostin, 1991](:bib:Starostin1991)), or as litmus test for dubious cases of language relationship which might be due to inheritance or borrowing ([McMahon et al., 2005](:bib:McMahon2005a); \n",
    "[Chén Bǎoyà 陈保亚, 1996](:bib:Chen1996);\n",
    "[Wang and Wang, 2004](:bib:Wang2004)).\n",
    "\n",
    "Apart from concept lists proposed for the application in\n",
    "historical linguistics, there is a large amount of not explicitly diachronic data, including concept lists serving as the\n",
    "basis for field work in specific linguistic areas ([Kraft, 1981](:bib:Kraft1981)),\n",
    "concept lists which serve as the basis for large surveys on\n",
    "specific linguistic phenomena ([Haspelmath and Tadmor, 2009](:bib:Haspelmath2009)), or concept lists which deal with the internal structuring of concepts, be it cognitive associations \n",
    "([Nelson et al., 2004](:bib:Nelson2004); [Hill et al., 2014](:bib:Hill2014)), cross-linguistic polysemies \n",
    "([List et al., 2014](:bib:List2014f)), or frequently recurring semantic shifts \n",
    "([Bulakh et al., 2013](:bib:Bulakh2013)). Concept lists play also an important role in\n",
    "education, where they are used to measure and aid learners’ progress ([Dolch, 1936](:bib:Dolch1936)), in psycholinguistics, where different kinds of word norm data, like frequency and concreteness, are needed to control for variables in experiments\n",
    "([Wilson, 1988](:bib:Wilson1988)), and in public health studies, where stan-\n",
    "dardized naming tests are used to assess the degree of apha-\n",
    "sia or language disturbance ([Nicholas et al., 1989](:bib:Nicholas1989); \n",
    "[Ardila, 2007](:bib:Ardila2007)).\n",
    "\n",
    "So in brief: there is a large number of different concept lists which has been used and is being actively used in different branches of science related to language, but which is not comparable directly, as scholars do not try to normalize the ways they name concepts in their elicitation glosses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3 Linking Concept Lists within the Concepticon Project\n",
    "\n",
    "The basic idea of the Concepticon reference catalog is to provide consistent links across the multitude of lexical questionnaires that linguists have been using to elicit words, be it during field work, for\n",
    "the purpose of establishing new datasets from published resources, or as a starting point for typological or\n",
    "historical language comparison. One major problem with the way people construct their questionnaires is\n",
    "that they have never been standardized across datasets, but were only considered to be applicable within one\n",
    "application. The Concepticon project tries to make up for this by linking the glosses that scholars use to\n",
    "elicit a certain meaning to concept sets which are themselves linked to additional metadata, such as a short\n",
    "definition, a rough semantic field, ontological categories (reflecting the more language-specific notion of\n",
    "part of speech), as well as additional metadata derived from norm datasets in psycholinguistics and natural language processing, including age-of-acquisition information for individual languages ([Kuperman et al. 2012](:bib:Kuperman2012)), ontologies like WordNet ([Princeton University 2010](:bib:Wordnet2010)), or word frequency counts, again for individual languages\n",
    "([Brysbaert and New 2009](:bib:Brysbaert2009)).\n",
    "\n",
    "In addition to the metadata, Concepticon concept sets can further be linked among each other with help\n",
    "of a simplifying ontology that identifies concept sets which are broader or narrower with respect to their\n",
    "denotation range. The concept set [ARM OR HAND](http://concepticon.clld.org/parameters/2121) for example, \n",
    "which is best represented by the Russian\n",
    "word *ruká*, insofar as it typically refers to the whole upper limb but also to the part which other languages\n",
    "denote as hand, is considered broader than\n",
    "[ARM](http://concepticon.clld.org/parameters/1277) and\n",
    "[HAND](http://concepticon.clld.org/parameters/1637).\n",
    "While scholars might object to this procedure, preferring to represent a comparative concept reflecting the semantics of Russian *ruká* by linking\n",
    "it to both ARM\n",
    "and HAND, it is important to emphasize that this practice, which may seem counterintuitive\n",
    "from the perspective of a given language, is indispensable to guarantee a rigorous mapping of word elicitation glosses in questionnaires to lexical comparative concepts. If a given questionnaire contains the gloss\n",
    "*arm/hand* (as we can find across many questionnaires which have been used to assemble a large number\n",
    "of data points) and we linked it to both ARM and HAND, we would lose the essential information\n",
    "that the original questionnaire was asking for the word expressing the concept that covers both concept sets\n",
    "in a single term. Since the ontology allows us to derive the information that ARM OR HAND is semantically broader than ARM and HAND, we could automatically turn the Concepticon data into a form where\n",
    "the elicitation gloss *arm/hand* links to both narrower concept sets, but we could not get back to the more\n",
    "rigorous representation.\n",
    "\n",
    "To inspect how the concepticon organizes this, let us look at a concrete example, namely the elicitation glosses linked to the concept set [FAT (ORGANIC SUBSTANCE)](http://concepticon.clld.org/parameters/323). \n",
    "\n",
    "The immediate advantage of linking data to the Concepticon is that it enables the merging of data from\n",
    "different sources quickly. Instead of working with ad-hoc solutions that would provide links between a\n",
    "range of different resources, it is much quicker to link different questionnaires to the Concepticon (leaving\n",
    "out those concepts which cannot be found, or adding them as new concepts). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4 Design Principles of Concept List Linking\n",
    "\n",
    "### 4.1 The Base File: `concepticon.tsv`\n",
    "\n",
    "### 4.2 Information on Concept Lists: `conceptlists.tsv`\n",
    "\n",
    "### 4.3 Concept Set Relations: `conceptrelations.tsv`\n",
    "\n",
    "### 4.4 Concrete Concept Lists in `conceptlists/`\n",
    "\n",
    "### 4.5 Concept Set Metadata in `concept_set_meta`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5 Fun with Concept Sets: `pyconcepticon` API\n",
    "\n",
    "\n",
    "To make sure that your data is comparable in terms of the concepts that you investigated, you should link your questionnaire to the Concepticon ([List et al. 2016](http://bibliography.lingpy.org?key=List2016a)). Many scholars still have a huge problem in understanding what the Concepticon actually is. We won't go into the details here, but if you are interested in selecting comparable questionnaires (e.g., words less prone to borrowing) for your language sample, you should definitely have a close look at the Concepticon website at http://concepticon.clld.org, since it is highly likely that your specific questionnaire has already been linked. In this case, you should download the concept list in the form in which it is provided by the Concepticon project, as this will spare you the time of typing it off yourself (which may introduce new errors), and you will get a lot of meta-information which may be useful. For example, if you download the Leipzig-Jakarta list ([Tadmor 2009](http://bibliography.lingpy.org?key=Tadmor2009), [Tadmor-2009-100](http://concepticon.clld.org/contributions/Tadmor-2009-100)), you may first learn a lot about how it was constructed, but you can also directly compare it with lists that may be similar. If you want to know how stable the concepts in this list are, for example, you could have a look at the basic list underlying the original project ([Haspelmath-2009-1460](http://concepticon.clld.org/contributions/Haspelmath-2009-1460)), where you will receive explicit ranks for all concepts.\n",
    "\n",
    "\n",
    "### 5.1 Comparing Concept Lists\n",
    "\n",
    "If you want to check the overlap between the Leipzig-Jakarta list and Swadesh's ([1955](http://bibliography.lingpy.org?key=Swadesh1955)) list of 100 items, you can use the Concepticon API, querying for the intersection of both lists:\n",
    "\n",
    "```shell\n",
    "$ concepticon intersection Tadmor-2009-100 Swadesh-1955-100\n",
    "  1   ARM OR HAND            [2121] HAND (1, Swadesh-1955-100)\n",
    "  2   ASH                    [646 ] \n",
    "  3   BIG                    [1202] \n",
    "  4   BIRD                   [937 ] \n",
    "  5   BITE                   [1403] \n",
    "  6   BLACK                  [163 ] \n",
    "  7   BLOOD                  [946 ] \n",
    "  8   BONE                   [1394] \n",
    "  9   BREAST                 [1402] \n",
    " 10   BURN                   [2102] BURNING (1, Tadmor-2009-100)\n",
    " 11   COME                   [1446] \n",
    " 12   DOG                    [2009] \n",
    " 13   DRINK                  [1401] \n",
    " 14   EAR                    [1247] \n",
    " 15   EARTH (SOIL)           [1228] \n",
    " 16   EAT                    [1336] \n",
    " 17   EGG                    [744 ] \n",
    " 18   EYE                    [1248] \n",
    " 19   FIRE                   [221 ] \n",
    " 20   FISH                   [227 ] \n",
    " 21   FLESH OR MEAT          [2615] \n",
    " 22   FLY (MOVE THROUGH AIR) [1441] \n",
    " 23   FOOT OR LEG            [2098] FOOT (1, Swadesh-1955-100)\n",
    " 24   GIVE                   [1447] \n",
    " 25   GO                     [695 ] WALK (1, Swadesh-1955-100)\n",
    " 26   GOOD                   [1035] \n",
    " 27   HAIR                   [1040] \n",
    " 28   HEAR                   [1408] \n",
    " 29   HORN (ANATOMY)         [1393] \n",
    " 30   I                      [1209] \n",
    " 31   KNEE                   [1371] \n",
    " 32   KNOW (SOMETHING)       [1410] \n",
    " 33   LEAF                   [628 ] \n",
    " 34   LIVER                  [1224] \n",
    " 35   LONG                   [1203] \n",
    " 36   LOUSE                  [1392] \n",
    " 37   MOUTH                  [674 ] \n",
    " 38   NAME                   [1405] \n",
    " 39   NECK                   [1333] \n",
    " 40   NEW                    [1231] \n",
    " 41   NIGHT                  [1233] \n",
    " 42   NOSE                   [1221] \n",
    " 43   NOT                    [1240] \n",
    " 44   ONE                    [1493] \n",
    " 45   RAINING OR RAIN        [2108] RAIN (PRECIPITATION) (1, Tadmor-2009-100)\n",
    " 46   RED                    [156 ] \n",
    " 47   ROOT                   [670 ] \n",
    " 48   SAND                   [671 ] \n",
    " 49   SAY                    [1458] \n",
    " 50   SEE                    [1409] \n",
    " 51   SKIN                   [763 ] \n",
    " 52   SMALL                  [1246] \n",
    " 53   SMOKE (EXHAUST)        [778 ] \n",
    " 54   STAND                  [1442] \n",
    " 55   STAR                   [1430] \n",
    " 56   STONE OR ROCK          [2125] STONE (1, Swadesh-1955-100)\n",
    " 57   TAIL                   [1220] \n",
    " 58   THIS                   [1214] \n",
    " 59   THOU                   [1215] \n",
    " 60   TONGUE                 [1205] \n",
    " 61   TOOTH                  [1380] \n",
    " 62 * TREE OR WOOD           [2141] WOOD (1, Tadmor-2009-100), \n",
    "                                    TREE (1, Swadesh-1955-100)\n",
    " 63   WATER                  [948 ] \n",
    " 64   WHAT                   [1236] \n",
    " 65   WHO                    [1235] \n",
    "```\n",
    "\n",
    "From this output, you can learn that Leipzig-Jakarta lists \"arm or hand\" as a concept, while Swadesh is more concrete, listing only \"hand\". You can also learn that Swadesh is not very concrete regarding the concept \"rain\" where he fails to inform us whether it was intended as a noun or a verb. From the match 62, you can further see that \"tree\" and \"wood\" are both judged to be subsets of the meta-concept \"tree or wood\", and indeed, there are quite a few languages which do not distinguish between the two.\n",
    "\n",
    "There are more possibilities: The ```concepticon union``` command allows you to calculate the union of different lists, thus allowing you to create your own questionnaires based on different concept lists. By typing the following command in the command line, for example, you can learn that the union of Leipzig-Jakarta and Swadesh's 100-item list are 135 concepts:\n",
    "\n",
    "```shell\n",
    "$ concepticon union Tadmor-2009-100 Swadesh-1955-100 | wc -l\n",
    "135\n",
    "```\n",
    "And if you add the 200-item list by Swadesh ([1952](http://bibliography.lingpy.org?key=Swadesh1952)), you will see that the union has 222 concepts:\n",
    "\n",
    "```shell\n",
    "$ concepticon union Tadmor-2009-100 Swadesh-1955-100 Swadesh-1952-200 | wc -l\n",
    "222\n",
    "```\n",
    "\n",
    "### 5.2 Linking Concept Listts\n",
    "\n",
    "More importantly, if you want to merge data from different questionnaires or datasets where your do not know to which degree concepts overlap, you can use the automatic mapping algorithm provided by the Concepticon API to get a first intelligent guess which concepts your data contains. This works even across different languages, as we have so far assembled concept labels in quite a few different language varieties which we can use to search for similar concepts. The command is a simple as typing ```concepticon map_concepts <yourconceptlist>``` in your terminal, where you replace ```<yourconceptlist>``` with your filename. We have prepared three files, one in English, one in Chinese, and one in German, all showing the following tabule structure (the following being from the file ```C_concepts.tsv```):\n",
    "\n",
    "```\n",
    "NUMBER\tENGLISH\n",
    "1\tword\n",
    "2\thand\n",
    "3\teggplant\n",
    "4\taubergine\n",
    "5\tsimpsons (tv series)\n",
    "```\n",
    "\n",
    "In order to link this English file to the Concepticon, all we have to do is to type:\n",
    "\n",
    "```shell\n",
    "$ concepticon map_concepts C_concepts.tsv\n",
    "NUMBER\tENGLISH\tCONCEPTICON_ID\tCONCEPTICON_GLOSS\tSIMILARITY\n",
    "1\tword\t1599\tWORD\t2\n",
    "2\thand\t1277\tHAND\t2\n",
    "3\teggplant\t1146\tAUBERGINE\t2\n",
    "4\taubergine\t1146\tAUBERGINE\t4\n",
    "5\tsimpsons (tv series)\t\t???\t\n",
    "#\t4/5\t80%\t\n",
    "```\n",
    "\n",
    "The output tells us first, whether the Concepts can be linked to Concepticon, and second, it gives us the overall percentage for inferred links. You can see that the mapping algorithm is not based on simple string identity, as it correctly links \"eggplant\" to the concept set ```AUBERGINE```.\n",
    "\n",
    "Similarly, we can try to link our file with Chinese concepts, the file ```C_concepts-chinese.tsv```:\n",
    "\n",
    "```shell\n",
    "$ concepticon --language=zh map_concepts C_concepts-chinese.tsv\n",
    "NUMBER\tGLOSS\tCONCEPTICON_ID\tCONCEPTICON_GLOSS\tSIMILARITY\n",
    "1\t我\t1209\tI\t2\n",
    "2\t你\t1215\tTHOU\t2\n",
    "3\t太陽\t1343\tSUN\t2\n",
    "4\t吃飯\t\t???\t\n",
    "5\t月亮\t1313\tMOON\t2\n",
    "#\t4/5\t80%\t\n",
    "```\n",
    "\n",
    "And accordingly also our file ```C_concepts-german.tsv```:\n",
    "\n",
    "```shell\n",
    "$ concepticon --language=de map_concepts C_concepts-german.tsv\n",
    "NUMBER\tGLOSS\tCONCEPTICON_ID\tCONCEPTICON_GLOSS\tSIMILARITY\n",
    "1\tHand\t1277\tHAND\t2\n",
    "2\tSchuh\t1381\tSHOE\t2\n",
    "3\tFuß\t1301\tFOOT\t2\n",
    "4\tAbend\t1629\tEVENING\t2\n",
    "5\tSonne\t1343\tSUN\t2\n",
    "#\t5/5\t100%\t\n",
    "```\n",
    "\n",
    "As a final example, let us see what the Concepticon API does if we encounter a \"fuzzy\" matching:\n",
    "\n",
    "```bash\n",
    "$ concepticon map_concepts C_concepts-fuzzy.tsv \n",
    "NUMBER\tENGLISH\tCONCEPTICON_ID\tCONCEPTICON_GLOSS\tSIMILARITY\n",
    "1\tword\t1599\tWORD\t2\n",
    "#<<<\t\t\t\t\n",
    "2\thand / arm\t1277\tHAND\t4\n",
    "2\thand / arm\t1019\tRIGHT\t4\n",
    "2\thand / arm\t244\tLEFT\t4\n",
    "2\thand / arm\t1673\tARM\t4\n",
    "2\thand / arm\t2121\tARM OR HAND\t4\n",
    "#>>>\t\t\t\t\n",
    "3\teggplant\t1146\tAUBERGINE\t2\n",
    "4\taubergine\t1146\tAUBERGINE\t4\n",
    "#<<<\t\t\t\t\n",
    "5\tman (male)\t1554\tMAN\t2\n",
    "5\tman (male)\t2106\tMALE PERSON\t2\n",
    "#>>>\t\t\t\t\n",
    "#\t5/5\t100%\t\n",
    "\n",
    "```\n",
    "\n",
    "Here, you can see that the concept labels \"hand / arm\" and \"man (male)\" are linked to multiple concept sets. The output further indicates which of those multiple links form a block: The characters \"#<<<\" in a line indicate the start, and the characters \"#>>>\" the end. This allows you to conveniently jump from block to block in order to select the best match (or manually add a better match). Note that mapping to the concepticon should NEVER link one concept in your data to two or more concept sets in the Concepticon. The linking to Concepticon is, as a requirement, always *n* to 1, with *n* ideally being 1 as well. \n",
    "\n",
    "<span style=\"color:red\">You may wonder why the API gives you certain similarity scores. For example, why would \"eggplant\" rank higher than \"aubergine\". The reason can be found in the specific mapping algorithm that we use and which may need future refinement. This algorithm essentially divides a \"gloss\" (a concept label) into different parts, and also tries to determine information regarding part of speech and the like. This algorithm is currently being revised, and we hope to be able to provide information soon.</span>\n",
    "\n",
    "### 5.3 Contributing to Concepticon\n",
    "\n",
    "The Concepticon is a collaborative effort that is supposed to render our linguistic data more comparable. The more questionnaires we can add to our collection, the easier it will be for future research to build on these resources. Even if you think that you do not need to link your data to Concepticon, since you anyway use the \"standard list\" by Swadesh, you should at least provide a ```concepts.tsv``` file in which you list your explicit links. In this way you guarantee that other can re-use your data and also contribute to the collaborative efforts which are currently being done in the context of the CLDF initiative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6 Caveats\n",
    "\n",
    "+++ write down some problems: Tiago's example from Tanzania language survey, Mattis' example on \"stupid\", Simon's example, and the example on tigre = Jaguar +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## References\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
