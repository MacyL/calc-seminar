{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Session 3: Concepticon (Johann-Mattis List and Tiago Tresoldi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1 Reference Catalogs\n",
    "\n",
    "While we often think of linguistic data in terms of a datapoint tied to a specific language variety or a specific language family, many aspects of linguistic data can be generalized. The most prominentt example would be language names, as the the names which scholars give to the language varieties they study may often vary (for different reasons, be it socio-cultural, traditions of specific scholarly fields, etc.), and these issues are differently addressed and may vary from study to study and dataset to dataset. Given that the first and foremost goal of computer-assisted approaches to historical language comparison is to make sure that data *is* comparable across applications, it is important to have some kind of authority that can be used in order to reference a given language variety. Since most linguists are anarchists deep down in their hearts, it is easy to understand that following some authority when writing papers or creating datasets where they include data of different language varieties, is not the first thing they think of when creating and curating cross-linguistic data. If a certain name is common for the variety they work on in their specific field of study, but the authorities give it another name which follows other fields, it is obvious that they don't want to use the name that most scholars use but rather the name that is most appropriate for their peers. \n",
    "\n",
    "This is where reference catalogs for language varieties come into play. A reference catalog of language names, geolocations, and expert classifications like the one offert by the [Glottolog](http://glottolog.org) project offers (a) unique identifiers for language names, (b) a release and update strategy to cope with errors in the data, or its expansion, and (c) exhaustive metadata (like references, classifications, etc.) linked to each of the unique identifiers. While scholars don't need to change the actual names they use to denote their language varieties in their work, all they need to do is to provide a mapping of the names they use and the identifiers provided by Glottolog in order to render their data comparable. But in contrast to what some scholars think, mapping language names in a given dataset to Glottolog does not result in unidirectional profit (from the scholar to the community), but instead enables those scholars who link their data to a reference catalog like Glottolog abundant amounts of metadata (references, classifications, geolocations), which they won't need to assemble themselves, since they are already there.\n",
    "\n",
    "This means, if scholars link their data to reference catalogs like Glottolog, both the community will profit, as scholars can easily find out which studies were devoted to which language varieties, while scholars who want to assemble linguistic data (mostly typologists and historical linguistics) can profit from the ground work on assigning metadata to languages that has been already done by the Glottolog editorial board.\n",
    "\n",
    "The idea of reference catalogs can be further expanded to other kinds of linguistic data. Concepts for example, are notoriously difficult to define, and yet scholars usually try to define them, as a lot of research is based on questionnaires where scholars assemble a list of concepts in some elicitation language and then go out to the field to ask their informations how they pronounce those concepts. Since questionnaires differ a lot, not only regarding the languages used for elicitation, but also regarding the specific conventions that scholars use to avoid the fuzziness of words in the eliciation language (e.g., distinction between noun and verb in words like *hand*), a catalog of concepts can help to render different studies comparable which are devoted to lexical data.\n",
    "\n",
    "Another example are phonetic transcriptions: Scholars often use different transcription systems, at times even customized variants, for several reasons like ease of typing, phonological considerations, or traditions in their field, but even if scholars use a system like the one proposed by the International Phonetic Alphabet, they may use it in slightly different ways. As a result, phonetic transcriptions are not necessarily directly comparable across datasets and studies. A reference catalog in which scholars provide their original transcriptions in a standardized form would again increase the comparability across datasets, but it would also be helpful for the scholars, as they could use such a reference catalog to receive information on additional aspects of sounds, such as common feature systems, general frequency distributions, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2 Background on Concept Lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3 Linking Concept Lists within the Concepticon Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4 Design Principles of Concept List Linking\n",
    "\n",
    "### 4.1 The Base File: `concepticon.tsv`\n",
    "\n",
    "### 4.2 Information on Concept Lists: `conceptlists.tsv`\n",
    "\n",
    "### 4.3 Concept Set Relations: `conceptrelations.tsv`\n",
    "\n",
    "### 4.4 Concrete Concept Lists in `conceptlists/`\n",
    "\n",
    "### 4.5 Concept Set Metadata in `concept_set_meta`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5 Fun with Concept Sets: `pyconcepticon` API\n",
    "\n",
    "\n",
    "To make sure that your data is comparable in terms of the concepts that you investigated, you should link your questionnaire to the Concepticon ([List et al. 2016](http://bibliography.lingpy.org?key=List2016a)). Many scholars still have a huge problem in understanding what the Concepticon actually is. We won't go into the details here, but if you are interested in selecting comparable questionnaires (e.g., words less prone to borrowing) for your language sample, you should definitely have a close look at the Concepticon website at http://concepticon.clld.org, since it is highly likely that your specific questionnaire has already been linked. In this case, you should download the concept list in the form in which it is provided by the Concepticon project, as this will spare you the time of typing it off yourself (which may introduce new errors), and you will get a lot of meta-information which may be useful. For example, if you download the Leipzig-Jakarta list ([Tadmor 2009](http://bibliography.lingpy.org?key=Tadmor2009), [Tadmor-2009-100](http://concepticon.clld.org/contributions/Tadmor-2009-100)), you may first learn a lot about how it was constructed, but you can also directly compare it with lists that may be similar. If you want to know how stable the concepts in this list are, for example, you could have a look at the basic list underlying the original project ([Haspelmath-2009-1460](http://concepticon.clld.org/contributions/Haspelmath-2009-1460)), where you will receive explicit ranks for all concepts.\n",
    "\n",
    "\n",
    "### 5.1 Comparing Concept Lists\n",
    "\n",
    "If you want to check the overlap between the Leipzig-Jakarta list and Swadesh's ([1955](http://bibliography.lingpy.org?key=Swadesh1955)) list of 100 items, you can use the Concepticon API, querying for the intersection of both lists:\n",
    "\n",
    "```shell\n",
    "$ concepticon intersection Tadmor-2009-100 Swadesh-1955-100\n",
    "  1   ARM OR HAND            [2121] HAND (1, Swadesh-1955-100)\n",
    "  2   ASH                    [646 ] \n",
    "  3   BIG                    [1202] \n",
    "  4   BIRD                   [937 ] \n",
    "  5   BITE                   [1403] \n",
    "  6   BLACK                  [163 ] \n",
    "  7   BLOOD                  [946 ] \n",
    "  8   BONE                   [1394] \n",
    "  9   BREAST                 [1402] \n",
    " 10   BURN                   [2102] BURNING (1, Tadmor-2009-100)\n",
    " 11   COME                   [1446] \n",
    " 12   DOG                    [2009] \n",
    " 13   DRINK                  [1401] \n",
    " 14   EAR                    [1247] \n",
    " 15   EARTH (SOIL)           [1228] \n",
    " 16   EAT                    [1336] \n",
    " 17   EGG                    [744 ] \n",
    " 18   EYE                    [1248] \n",
    " 19   FIRE                   [221 ] \n",
    " 20   FISH                   [227 ] \n",
    " 21   FLESH OR MEAT          [2615] \n",
    " 22   FLY (MOVE THROUGH AIR) [1441] \n",
    " 23   FOOT OR LEG            [2098] FOOT (1, Swadesh-1955-100)\n",
    " 24   GIVE                   [1447] \n",
    " 25   GO                     [695 ] WALK (1, Swadesh-1955-100)\n",
    " 26   GOOD                   [1035] \n",
    " 27   HAIR                   [1040] \n",
    " 28   HEAR                   [1408] \n",
    " 29   HORN (ANATOMY)         [1393] \n",
    " 30   I                      [1209] \n",
    " 31   KNEE                   [1371] \n",
    " 32   KNOW (SOMETHING)       [1410] \n",
    " 33   LEAF                   [628 ] \n",
    " 34   LIVER                  [1224] \n",
    " 35   LONG                   [1203] \n",
    " 36   LOUSE                  [1392] \n",
    " 37   MOUTH                  [674 ] \n",
    " 38   NAME                   [1405] \n",
    " 39   NECK                   [1333] \n",
    " 40   NEW                    [1231] \n",
    " 41   NIGHT                  [1233] \n",
    " 42   NOSE                   [1221] \n",
    " 43   NOT                    [1240] \n",
    " 44   ONE                    [1493] \n",
    " 45   RAINING OR RAIN        [2108] RAIN (PRECIPITATION) (1, Tadmor-2009-100)\n",
    " 46   RED                    [156 ] \n",
    " 47   ROOT                   [670 ] \n",
    " 48   SAND                   [671 ] \n",
    " 49   SAY                    [1458] \n",
    " 50   SEE                    [1409] \n",
    " 51   SKIN                   [763 ] \n",
    " 52   SMALL                  [1246] \n",
    " 53   SMOKE (EXHAUST)        [778 ] \n",
    " 54   STAND                  [1442] \n",
    " 55   STAR                   [1430] \n",
    " 56   STONE OR ROCK          [2125] STONE (1, Swadesh-1955-100)\n",
    " 57   TAIL                   [1220] \n",
    " 58   THIS                   [1214] \n",
    " 59   THOU                   [1215] \n",
    " 60   TONGUE                 [1205] \n",
    " 61   TOOTH                  [1380] \n",
    " 62 * TREE OR WOOD           [2141] WOOD (1, Tadmor-2009-100), \n",
    "                                    TREE (1, Swadesh-1955-100)\n",
    " 63   WATER                  [948 ] \n",
    " 64   WHAT                   [1236] \n",
    " 65   WHO                    [1235] \n",
    "```\n",
    "\n",
    "From this output, you can learn that Leipzig-Jakarta lists \"arm or hand\" as a concept, while Swadesh is more concrete, listing only \"hand\". You can also learn that Swadesh is not very concrete regarding the concept \"rain\" where he fails to inform us whether it was intended as a noun or a verb. From the match 62, you can further see that \"tree\" and \"wood\" are both judged to be subsets of the meta-concept \"tree or wood\", and indeed, there are quite a few languages which do not distinguish between the two.\n",
    "\n",
    "There are more possibilities: The ```concepticon union``` command allows you to calculate the union of different lists, thus allowing you to create your own questionnaires based on different concept lists. By typing the following command in the command line, for example, you can learn that the union of Leipzig-Jakarta and Swadesh's 100-item list are 135 concepts:\n",
    "\n",
    "```shell\n",
    "$ concepticon union Tadmor-2009-100 Swadesh-1955-100 | wc -l\n",
    "135\n",
    "```\n",
    "And if you add the 200-item list by Swadesh ([1952](http://bibliography.lingpy.org?key=Swadesh1952)), you will see that the union has 222 concepts:\n",
    "\n",
    "```shell\n",
    "$ concepticon union Tadmor-2009-100 Swadesh-1955-100 Swadesh-1952-200 | wc -l\n",
    "222\n",
    "```\n",
    "\n",
    "### 5.2 Linking Concept Listts\n",
    "\n",
    "More importantly, if you want to merge data from different questionnaires or datasets where your do not know to which degree concepts overlap, you can use the automatic mapping algorithm provided by the Concepticon API to get a first intelligent guess which concepts your data contains. This works even across different languages, as we have so far assembled concept labels in quite a few different language varieties which we can use to search for similar concepts. The command is a simple as typing ```concepticon map_concepts <yourconceptlist>``` in your terminal, where you replace ```<yourconceptlist>``` with your filename. We have prepared three files, one in English, one in Chinese, and one in German, all showing the following tabule structure (the following being from the file ```C_concepts.tsv```):\n",
    "\n",
    "```\n",
    "NUMBER\tENGLISH\n",
    "1\tword\n",
    "2\thand\n",
    "3\teggplant\n",
    "4\taubergine\n",
    "5\tsimpsons (tv series)\n",
    "```\n",
    "\n",
    "In order to link this English file to the Concepticon, all we have to do is to type:\n",
    "\n",
    "```shell\n",
    "$ concepticon map_concepts C_concepts.tsv\n",
    "NUMBER\tENGLISH\tCONCEPTICON_ID\tCONCEPTICON_GLOSS\tSIMILARITY\n",
    "1\tword\t1599\tWORD\t2\n",
    "2\thand\t1277\tHAND\t2\n",
    "3\teggplant\t1146\tAUBERGINE\t2\n",
    "4\taubergine\t1146\tAUBERGINE\t4\n",
    "5\tsimpsons (tv series)\t\t???\t\n",
    "#\t4/5\t80%\t\n",
    "```\n",
    "\n",
    "The output tells us first, whether the Concepts can be linked to Concepticon, and second, it gives us the overall percentage for inferred links. You can see that the mapping algorithm is not based on simple string identity, as it correctly links \"eggplant\" to the concept set ```AUBERGINE```.\n",
    "\n",
    "Similarly, we can try to link our file with Chinese concepts, the file ```C_concepts-chinese.tsv```:\n",
    "\n",
    "```shell\n",
    "$ concepticon --language=zh map_concepts C_concepts-chinese.tsv\n",
    "NUMBER\tGLOSS\tCONCEPTICON_ID\tCONCEPTICON_GLOSS\tSIMILARITY\n",
    "1\t我\t1209\tI\t2\n",
    "2\t你\t1215\tTHOU\t2\n",
    "3\t太陽\t1343\tSUN\t2\n",
    "4\t吃飯\t\t???\t\n",
    "5\t月亮\t1313\tMOON\t2\n",
    "#\t4/5\t80%\t\n",
    "```\n",
    "\n",
    "And accordingly also our file ```C_concepts-german.tsv```:\n",
    "\n",
    "```shell\n",
    "$ concepticon --language=de map_concepts C_concepts-german.tsv\n",
    "NUMBER\tGLOSS\tCONCEPTICON_ID\tCONCEPTICON_GLOSS\tSIMILARITY\n",
    "1\tHand\t1277\tHAND\t2\n",
    "2\tSchuh\t1381\tSHOE\t2\n",
    "3\tFuß\t1301\tFOOT\t2\n",
    "4\tAbend\t1629\tEVENING\t2\n",
    "5\tSonne\t1343\tSUN\t2\n",
    "#\t5/5\t100%\t\n",
    "```\n",
    "\n",
    "As a final example, let us see what the Concepticon API does if we encounter a \"fuzzy\" matching:\n",
    "\n",
    "```bash\n",
    "$ concepticon map_concepts C_concepts-fuzzy.tsv \n",
    "NUMBER\tENGLISH\tCONCEPTICON_ID\tCONCEPTICON_GLOSS\tSIMILARITY\n",
    "1\tword\t1599\tWORD\t2\n",
    "#<<<\t\t\t\t\n",
    "2\thand / arm\t1277\tHAND\t4\n",
    "2\thand / arm\t1019\tRIGHT\t4\n",
    "2\thand / arm\t244\tLEFT\t4\n",
    "2\thand / arm\t1673\tARM\t4\n",
    "2\thand / arm\t2121\tARM OR HAND\t4\n",
    "#>>>\t\t\t\t\n",
    "3\teggplant\t1146\tAUBERGINE\t2\n",
    "4\taubergine\t1146\tAUBERGINE\t4\n",
    "#<<<\t\t\t\t\n",
    "5\tman (male)\t1554\tMAN\t2\n",
    "5\tman (male)\t2106\tMALE PERSON\t2\n",
    "#>>>\t\t\t\t\n",
    "#\t5/5\t100%\t\n",
    "\n",
    "```\n",
    "\n",
    "Here, you can see that the concept labels \"hand / arm\" and \"man (male)\" are linked to multiple concept sets. The output further indicates which of those multiple links form a block: The characters \"#<<<\" in a line indicate the start, and the characters \"#>>>\" the end. This allows you to conveniently jump from block to block in order to select the best match (or manually add a better match). Note that mapping to the concepticon should NEVER link one concept in your data to two or more concept sets in the Concepticon. The linking to Concepticon is, as a requirement, always *n* to 1, with *n* ideally being 1 as well. \n",
    "\n",
    "<span style=\"color:red\">You may wonder why the API gives you certain similarity scores. For example, why would \"eggplant\" rank higher than \"aubergine\". The reason can be found in the specific mapping algorithm that we use and which may need future refinement. This algorithm essentially divides a \"gloss\" (a concept label) into different parts, and also tries to determine information regarding part of speech and the like. This algorithm is currently being revised, and we hope to be able to provide information soon.</span>\n",
    "\n",
    "### 5.3 Contributing to Concepticon\n",
    "\n",
    "The Concepticon is a collaborative effort that is supposed to render our linguistic data more comparable. The more questionnaires we can add to our collection, the easier it will be for future research to build on these resources. Even if you think that you do not need to link your data to Concepticon, since you anyway use the \"standard list\" by Swadesh, you should at least provide a ```concepts.tsv``` file in which you list your explicit links. In this way you guarantee that other can re-use your data and also contribute to the collaborative efforts which are currently being done in the context of the CLDF initiative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6 Caveats\n",
    "\n",
    "+++ write down some problems: Tiago's example from Tanzania language survey, Mattis' example on \"stupid\", Simon's example, and the example on tigre = Jaguar +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
