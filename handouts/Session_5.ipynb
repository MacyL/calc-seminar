{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 5: CLTS (Cormac Anderson, Johann-Mattis List, and Tiago Tresoldi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "\n",
    "As we discussed when dealing with Concepticon in Session #3, contrary to what non-practitioners might expect, the systems of phonetic notation used by linguists are highly idiosyncratic. Not only do various linguistic subfields disagree on the specific symbols they use to denote the speech sounds of languages, but also in large databases of sound inventories considerable variation can be found. Inspired by other efforts to link cross-linguistic data with help of reference catalogues (such as Glottolog and Concepticon) across different resources, we have also focused in linking different phonetic notation systems to a catalogue of speech sounds. This is achieved with the help of a database accompanied by a software framework that uses a limited but easily extendable set of non-binary feature values to allow for quick and convenient registration of different transcription systems, while at the same time linking to additional datasets with restricted inventories. Linking different transcription systems enables us to conveniently translate between different phonetic transcription systems, linking sounds to databases allows users quick access to various kinds of metadata, including feature values, statistics on phoneme inventories, and information on prosody and sound classes.\n",
    "\n",
    "Phonetic transcription has a long tradition in historical linguistics. Efforts to design a unified transcription system capable of representing and distinguishing all the sounds in the languages of the world go back to the late 19th century, culminating with the efforts of the International Phonetic Association (see [Kalusky 2017:7f](:bib:Kalusky2017)). In contrast to writing systems targeted at encoding the speech of a single language variety in a visual medium, phonetic transcription aims at representing different kinds of speech in a unified system, which ideally would enable those trained in the system to reproduce foreign speech directly.\n",
    "Apart from the primary role which phonetic transcription plays in teaching foreign languages, it is also indispensable for the purposes of language comparison, both typological and historical. In this sense, the symbols which scholars use in order to transcribe speech sounds, that is, the graphemes, which we understand as sequences of one or more glyphs, serve as comparative concepts in the sense of [Haspelmath (2010)](:bib:Haspelmath2010). While the usefulness of phonetic transcription may be evident to typologists interested in the diversity of speech sounds (although see critiques of this approach to phonological typology, i.a. Simpson ([1999](:bib:Simpson1999)), the role of unified transcription systems like the International Phonetic Alphabet (IPA) is often regarded as less important in historical linguistics, where scholars often follow the algebraic tradition of [Saussure (1916)](:bib:Saussure1916) (already implicit in [Saussure 1878](:bib:Saussure1878)). This emphasises the systematic aspect of  historical language comparison, in which the distinctiveness of sound units within a system is more important than how they compare in substance across a sample of genetically related languages. If we leave the language-specific level of historical language comparison, however, and investigate general patterns of sound change in the languages of the world, it is obvious that this can only be done with help of comparable transcription systems serving as comparative concepts. \n",
    "\n",
    "When dealing with phonetic transcriptions, it is useful to distinguish transcription systems from transcription data. The former describe a set of symbols and rules for symbol combinations which can be used to represent speech in the medium of writing, while the latter result from the application of a given transcription system and aim at displaying linguistic diversity in terms of sound inventories or lexical datasets. While transcription systems are generative in that they can be used to encode sounds by combining the basic material, transcription data are static and fixed in size (at least for a given version published at a certain point in time). Transcription data have become increasingly important, with recent efforts to provide cross-linguistic accounts of sound inventories ([Moran et al. 2014](:bib:Moran2014), [Maddieson et al. 2013](:bib:Maddieson2013)), but in some sense, we can say that every dictionary or word list that aims at representing the pronunciation of a language can be considered as transcription data in a broad sense. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Comparability of Transcription Systems and Data\n",
    "\n",
    "When dealing with transcription systems and transcription data, linguists face several problems. Some of these are problems of a practical nature, which we explore further below, while others are of a theoretical nature, and touch upon long-standing issues in phonology and phonetics, and the relationship between the two. Among these theoretical problems, are the those of commensurability, of context, and of resolution. \n",
    "In spite of frequent attempts to compare phonemic inventories in phonological typology ([Dryer and Haspelmath 2011](:bib:Wals2011), [Maddieson 1984](:bib:Maddieson1984)) these efforts are beset by serious difficulties. The classical structuralist treatment of the phoneme considers it to be a relational entity ([Trubetzkoy 1939](:bib:Trubetzkoy1939a)), the value of which is dependent on its place with respect to other phonemes within a system. In this understanding, the phonemes of one language are not commensurate to those of another language: it is only as a member of a system that a phoneme finds its value. This critique is taken up by Simpson ([1999](:bib:Simpson1999)) who argues that the allophone replaces the phoneme in large databases, thereby reducing  “the phonemic system of a language to a small, arbitrary selection of its phonetics”. Although this problem cannot really be resolved, we note that different phonological databases have attempted to address it in different ways. In LAPSyD [Maddieson et al. 2013](:bib:Maddieson2013)), the symbols chosen for the phonemes are often frequently occurring ones, abstracting away from too much phonetic detail. In PHOIBLE ([Moran et al. 2014](:bib:Moran2014), on the other hand, phonemes are often transcribed with great phonetic detail, with numerous diacritics. While at first glance the latter approach might appear preferable, as it gives more information, it runs into serious difficulties, given Simpson’s critique above.\n",
    "\n",
    "The crux of this problem is that the realisation of a given phoneme depends considerably on context. For example, the German stops typically transcribed /b/, /d/, and /g/ are pronounced voiceless when in final position, whereas between vowels they are pronounced with voice. In European Spanish, the voiced stops /b/, /d/ and /g/ only occur with the phonetic values [b],  [d], and [g] in initial position, whereas elsewhere they are invariably pronounced as fricatives [β],  [ð], and [ɣ]. It is not clear, in such cases, which set of symbols should be used, and even if a principled decision could be made (e.g. based on frequency, [Bybee 2001](:bib:Bybee2001)), a great loss of information is involved in choosing one symbol over the other – it is equally misleading to characterise Spanish as a language without voiced stops or as a language without voiced fricatives. Such difficulties are not only of relevance in phonological typology, but  can have serious repercussions in historical linguistics as well. To take an example, linguists typically transcribe two series of stops in Scottish Gaelic – aspirated /pʰ/, /tʰ/, and /kʰ/ and unaspirated /p/, /t/, and /k/. In Modern Irish, on the other hand, the convention is to transcribe rather voiceless /p/, /t/, and /k/ and voiced /b/, /d/, and /g/. In reality, however, the voiceless stops of Irish are also aspirated, and the voiced ones are only passively voiced (i.e. it is an ‘aspirating’ language in the parlance of laryngeal typology (Honeybone 2005[:bib:Honeybone2005])). The difference between these two very closely related languages lies solely in the fact that in Irish there is perhaps a greater tendency to passively voice the second series. To a naïve historical linguist, however (or indeed, to an even more naïve algorithm), this minor difference would seem a highly significant one, and would require the postulation of entirely spurious sound changes (“deaspiration” and “voicing” of the two Irish series, for example) to account for the difference.\n",
    "\n",
    "\n",
    "This last example leads to a further difficulty: the level of resolution of the different transcription datasets available varies widely. Sapir ([1930](:bib:Sapir1930)) gives an extremely detailed account of the phonological system of Southern Paiute, very rich in phonetic detail. However, in our only description of the closely-related language Chemehuevi ([Press 1980](:bib:Press1980)) there is a comparative paucity of discussion of phonetic particulars. This is not to criticise her grammar (indeed one could make exactly the opposite statement about the quality of the syntactic description in her grammar and Sapir’s), but rather to recognise that these two sets of transcription data have a very different level of resolution. Obviously, there are great difficulties inherent in comparing datasets of differing levels of resolution: absence of evidence (e.g. in some phonetic particular of Chemehuevi) does not equate to evidence of absence. Our degree of knowledge about the phonetics and phonology of the languages of the world varies greatly, from practically nothing to voluminous descriptions detailing small sociolectal, dialectal, and idiolectal divergences.\n",
    "\n",
    "One might ask then, given these difficulties we recognise, what the value of this enterprise is. We believe that notwithstanding these theoretical difficulties, some practical progress can still be made. Given that transcription systems are rarely standardised in a rigid manner, and allow for a certain amount of freedom of choice, scholars have come up with many ad-hoc solutions which are reflected in specific traditions which have developed in different sub-fields of comparative linguistics. As we have seen above, in different linguistic traditions there are specific particularities in the representation of sounds in a written medium. Scholars are usually aware of these differences in their field of expertise, but when it comes to global accounts of phonetic and phonological diversity, the particularities of the different traditions may easily introduce errors in our analyses. A great number of the difficulties arise not from the broader theoretical problems outlined above, but from exactly these idiosyncrasies of tradition or personal taste. In some cases, different linguists represent sounds which are fundamentally the same in different ways (see, for instance, the examples from Pacific languages in 2.1.4). Convenience also plays a role here: as it is inconvenient to write a superscript ‹h› to mark aspiration of a stop, scholars often just use the normal ‹h› instead, assuming that their colleagues will understand, when reading the introduction to their field work notes or grammars. An ‹h› following a stop, however, does not necessarily point to aspiration in all linguistic traditions. In Australian linguistics, for example, it often denotes a laminal stop ([Dench 2002](:bib:Dench2002)). \n",
    "\n",
    "Further problems that scholars who work in a qualitative framework may not even realise arise from the nature of Unicode, which offers different encodings for characters that look the same ([Cysouw and Moran 2017: 54](:bib:Cysouw2017)). While scholars working qualitatively will have no problems to see that ‹ə› (Unicode 0259, Latin Small Letter Schwa) and ‹ə› (Unicode 01DD, Latin Small Letter Turned E) are identical, the two symbols are different for a computer, as they are represented internally by different code points. As a result, an automatic aggregation of data will treat these symbols as different sounds when comparing languages automatically, or when aggregating information on sound inventories of the languages in the world. \n",
    "\n",
    "Judging from the above-mentioned examples, we can identify identify three major problems which make it hard for us to compare phonetic transcriptions cross-linguistically, namely the problem of (a) errors introduced due to the wrong application of the Unicode standard, (b) general incomparability due to the use of different transcription systems, and (c) ambiguities introduced by scholars due to individual transcription preferences. In order to render our transcription systems and datasets cross-linguistically comparable, both for humans and for machines, it therefore seems indispensable to work on a system that normalizes transcriptions across different transcription systems and transcription data by linking existing transcription systems and datasets to a unified standard. Such a system should ideally (a) ease the process of writing phonetic transcriptions (e.g., by providing tools that automatically check and normalize transcriptions while scholars are creating them), (b) ease the comparison of existing transcriptions (e.g., by providing an internal reference point for a given speech sound which links to different grapheme representations in different transcription systems and datasets), and (c) provide a standard against which scholars can test existing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Usage\n",
    "\n",
    "![CLTS](img/clts.png)\n",
    "\n",
    "### 3.1 Basic sound classes\n",
    "\n",
    "| Class     | Grapheme | Features                                                     |\n",
    "|-----------|----------|--------------------------------------------------------------|\n",
    "| consonant | kʷʰ      | labialized aspirated velar stop                              |\n",
    "| vowel     | ṵ        | creaky rounded close back                                    |\n",
    "| cluster   | kp       | from voiceless velar stop to voiceless bilabial stop         |\n",
    "| diphthong | au̯       | from unrounded open front to non-syllabic rounded close back |\n",
    "| tone      | ²¹⁴      | contour from-mid-low via-low to-mid-high                     |\n",
    "| marker    | +        | marker for morpheme boundaries                               |\n",
    "\n",
    "### 3.2 Confusables\n",
    "\n",
    "| Source | Source Code | Target | Target Code | Sound Name                                         |\n",
    "|--------|-------------|--------|-------------|----------------------------------------------------|\n",
    "| λ      | 03BB        | ʎ      | 028E        | palatalized alveolar lateral approximant consonant |\n",
    "| ǝ      | 01DD        | ə      | 0259        | unrounded mid central vowel                        |\n",
    "| ɂ      | 0242        | ʔ      | 0294        | voiceless glottal stop consonant                   |\n",
    "| ε      | 03B5        | ɛ      | 025B        | unrounded open-mid front                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Examples\n",
    "\n",
    "![CLTS Site](img/clts_site.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
