{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Multi-tiered sequence representation\n",
    "\n",
    "### Pseudo words and phonological rules\n",
    "\n",
    "When dealing with questions of historical phonology (but also synchronic phonology), linguists often forget to make clear to themselves what questions they want to investigate in the end. Apart from the large pool of potential questions that can be asked when dealing with phonological questions, we consider especially the following three tasks as important, especially from the perspective of computable applications:\n",
    "\n",
    "1. (pseudo) word generation: the generation by whatever means of all *possible* sounds of a given language\n",
    "2. phonological rule induction: the induction (inference) of rules that trigger phonological changes in \n",
    "  - diachrony (from a source language to a target language), but also in \n",
    "  - synchrony (from a set of source forms to target forms within the same language)\n",
    "3. (pseudo) word prediction: the prediction of the possible outcome of a phonological process by which a source word form is converted, using a set of phonological rules, to a target form, again in\n",
    "  - diachrony (from an ancestral form to a descendant form), and again also\n",
    "  - synchrony (from a source form `[`or underlying form`]` to a target form `[`or surface form`]`)\n",
    "  \n",
    "These tasks do not cover all of phonology and phonological theory, but they capture many aspects that are dealt with in many schools of phonology, including generative syntax, optimality theory, and also classical historical linguistics.\n",
    "\n",
    "The task of (pseudo) word generation can be seen as the fundamental task of many approaches to phonology. If we assume that phonology defines phonotactic rules for a given language by which a set of symbols (the phonemes of the language) are transformed into valid forms of the language under investigation, which will be readily accepted as possible words of that very languages by its native speakers, can often be found in the phonological literature, even if it is rarely addressed by the authors explicitly. In traditional grammars of a language, for example, we often find a chapter on the phonotactics of a given language, where the authors describe the general syllable structure, using well-known formulas, such as `(C)(C)V(C)`, by which the general structure of possible syllables is described (with C referring to consonants and V referring to vowels). We can also find it in more theoretical accounts of phonology where scholars try to explain why a certain language does not allow for specific words. \n",
    "\n",
    "Word generation is also reflected in spoken language itself, as we can easily test when asking native speakers of a given language, whether some word that we just artificially created might form a possible word in their native tongue. We can find extreme limitations in the phonotactic systems of the languages of the world, where almost all possible words or syllables are valid. In Mandarin Chinese, for example, the amount of possible syllables (and syllables also correspond to morphemes) is limited to about 1600 different forms, of which, however, only about 1200 are readily realized in the language. If you ask a Chinese speaker whether *ká* is a valid word in Mandarin Chinese, most would probably answer that this is the case, even if no morpheme or word exists, in which you can find this form. But if you ask them, whether *tré* is a valid form, the would almost certainly deny it. \n",
    "\n",
    "In languages with a more complex phonology, like German, it is more difficult to determine which words are potentially valid German words. Since pseudo words play an important role for psycholinguistic experiments ([Keyleers and Brysbaert 2010](:bib:Keyleers2010)), the unbiased generatoin of pseudo-words in different languages plays a crucial practical role for the research. But also in classical phonology, scholars discuss to which degree words that are possible but not reflected in a given language occur. Software for pseudo-word generation exists (Keuleers and Brysbaert 2010), but most of the time, psycholinguists generate their pseudo-word candidates for their experiments manually, usually by shuffling syllables. Given that the inference and description and comparison of the phonotactic rules underlying a given language are a typical example for the fundamental research with which classical phonology should be concerned, it is surprising that the tasks of pseudo word generation and phonotactic description are barely addressed from within the same framework. We think that it is crucial, especially for computer-assisted accounts on historical linguistics (but also synchronic phonology), to emphasize the similarity between the tasks and to work on unified frameworks in which these task can be tackled both from a computational and a theoretical perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The two remaining tasks (rule inference and word prediction) are tightly connected with phonotactics, even if this may not seem to be obvious at the first sight. The similarity lies not only in the importance of the phonotactics of a given language to license a specific output (that needs to conform to the phonotactical rules of the target language), but more specifically in the dominance of the concept of phonetic or phonological context that plays a crucial role in both phonotactics and phonological change. From the phonotactic perspective, we can say that a language like German does not allow for voiced plosives (`[`b, d, g`]`) in the end of a word. From the perspective of phonological change, we can say that all voiced plosives in German words, if they occur in the end of the word, will be devoiced (`[`b, d, g`]` > `[`p, t, k`]` / `_`$). This rule results in morphonological alternations of voiced and voiceless plosives in the German plural (`[` h u n t `]` \"the dog\" vs. `[` h u n d ə `]` \"the dogs\").  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "While rules and patterns such as final devoicing seem to be easy enough to handle in whatever framework, we have seen that the role that *context* (in whatever flavor it occurs) plays in synchronic and diachronic phonology can be quite complex, and that models of word generation that restrict the probability of finding an element in some position in a sound sequence only depend on the preceding segment will often hopelessly fail. We could handle final devoicing in German with these models by simply assuming a word generator that never ends a word in a voiced plosive, but we would fail in various other tasks, be they related to phonotactics, or historical sound change). +++ maybe one example +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That we cannot use simple models in which the probability of finding a given sound only depends on the preceding sound, is unfortunate, since these models, which are usually called +++first order+++ Markov models, are very well investigated, and a large number of tools is available that could be directly used to investigate language data in empirical frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problems of current accounts in synchronic and diachronic phonology\n",
    "\n",
    "If we consider how phonology deals with the problems of word generation, rule inference, and word prediction, we can see several problems. These problems do not pertain to the theory of restrictions and rules (our tasks 1 and 2) *per se*, but rather in the procedures used by linguists to infer those restrictions and rules. The general problem is that the inference of restrictions and rules is a hard task: we always deal with a multitude of possibilities, but linguists have the ambition to find the *best* ones among these possibilities without being very concrete about what would qualify as an \"optimal\" restriction or rule to describe a given language. Linguists invoke various concepts, ranging from *cross-linguistic considerations* (rules recurring in many languages, and thus having predictive force beyond the description of one single language), *parsimony* (claiming that their account requires less assumptions than a given account by their colleagues), or *elegance* (as we can also often find it in mathematics, although there is no real criterion to judge the elegance of a given proposal). \n",
    "\n",
    "In general, the question of how to infer the rules is chiefly ignored in most approaches, probably also, because heuristic procedures that would confront scholars with all possible explanations for restrictions and rules would deprive scholars of the fun of trying to come up with new rules themselves. As a result, most accounts on phonology are restricted to the anecdotal, often only seemingly formal explanation of carefully ecclected phenomena, and discussions rarely focus on the data, but are restricted to carefully chose examples by which scholars try to make the point that their given system explains the few phenomena considered in a given study better than previous account. What we need, however, are rigorous empirical proposals that do no longer focus on exceptions and extremely challenging cases, but instead try to prove their usefulness based on a clear-cut set of principles that could ideally be applied to as many languages as possible. Ideally, each new account on phonological modeling should be tested on a large range of languages, and should be able to show that the tasks of word generation (1) and word prediction (3) are handled in a better way than previous accounts.\n",
    "\n",
    "What counts as *better* in this context is of course difficult to assess, but we think that a valid phonological theory should be based on parsimony with respect to a large sample of different languages. It should further be empirical and exhaustive, thus explaining not only the most challenging restrictions or exceptions, but ideally account for a very large number of words in the languages under consideration. \n",
    "\n",
    "What phonology needs, furthermore, is a clear-cut procedure for rule inference that, similar to recent attempts in mathematics to infer possible proofs computationally (see [automated proof checking](https://en.wikipedia.org/wiki/Automated_proof_checking) on Wikipedia), can also be automated, at least to some degree, in order to make sure that the initial inference of rules is not biased by the respective phonological school from which a proposal is derived. Another example for rule inference are recent applications in spreadsheet software, where tools like Microsoft's Excel try to infer the next value in a cell, after users have provided limited input for a certain range of cells (see [Gulwani 2011](:bib:Gulwani2011) for examples). As an example for the task of rule inference that software like Excel tries to accomplish here, consider sequences of numbers, such as 1, 3, 5, ? or 1, 2, 4, 7, 11, ?, and try to add the missing value. These tasks are similar to the task of rule inference in linguistics in so far as a couple of examples is given (and the possibility to further increase the number of examples, by further checking the data), and the taks is to infer how these examples can be explained with help of some rule or some set of rules. This comes very close to the task at hand in historical (and synchronic) phonology: based on either a set of words representing possible words in a language (our task number 1: word generation) or input-output examples where a couple of word pairs of which the second should be derived from the first is given, we try to infer the process that generates new words (task 1) or the rules by which we generate the output if we are given some input (task 2). Once we have inferred all rules, we can of course also generate the output of a given word for which we are only given the input (task 3).\n",
    "\n",
    "It is obvious that the tasks of rule inference has so far been only carried out manually in linguistics. Scholars rarely discuss heuristics describing how one could identify what relates an input to an output form, although it would, of course, be desirable to have either a computer-assisted or even a fully computer-based routine, not only because it would save us a lot of time, but also because it would help us to check the claims that a given inference of a set of rules is to be preferred over an alternative solution. \n",
    "\n",
    "The problem of inferring rules conditioning sound changes or restricting the possible words of a given language is that the phenomena we are dealing with are not entirely *simple*: what can follow a given sound in a language does not always only depend on what preceded it. Furthermore, we may have to accept that extra-phonological factors also have an impact on what we consider as possible words and what we neglect. \n",
    "\n",
    "As an example, consider four-consonant clusters in German, which can only occur after short vowels, like in *Herbst* \"autumn\", *färbst* \"(you) color\", *stirbst* \"you die\", or *kalbst* \"(you) give birth to a calf\". The sequences *rbst* and *lbst* are extreme clusters in the German languages which are really rare and -- apart from *Herbst* -- restricted to verbs, where *-st* marks the second person singular. If we create a pseudo word *nurbst* in German, it is without question that German speakers can pronounce this word, and it is also likely that they would accept it as a possible German word form. However, based on my intuition as a native speaker, I would predict that speaker would have a harder time licensing the word as \"German\", if it was proposed as *der Nurbst* as compared to *du nurbst*, simply, because the consonant combination is more often encountered as a complex morpheme (where speakers thus detect the verbal ending for the second person and interprete it accordingly) than as a single morpheme (where *Herbst* is our only exemplar in German). \n",
    "\n",
    "We would thus assume that restrictions and rules may -- at least to some degree -- have some *stochastic* component that cannot entirely be derived from the phonology alone. If this is the case, this clearly shows that we need models that allow for the inclusion of \"extra-phonological\" information, both for the task of word generation and of rule induction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Regular expressions and multiple levels of representation\n",
    "\n",
    "### Syllable templates \n",
    "\n",
    "Given the complexity of the problem of rule induction, scholars often do not completely address these problems, but make use of certain shortcuts. One example for such a shortcut are templates for possible syllables in a given language. A typical representation of the Chinese syllable structure, for example, is the one given by [Sun (2006: 3](:bib:Sun2006):\n",
    "\n",
    "> That is, the canonical syllable structure in Chinese can be represented by the following: (C)(M)V(V/N). In other words, in standard Chinese a syllable may exist as a single vowel [...] or possibly consist of a string of phones [...] with a syllable structure like CMVV [...] or CMVN.\n",
    "\n",
    "Let us have a closer look at this description by inspecting some concrete examples of this structure. First of all, C in Sun's description represents one of the consonants in Standard Chinese. They are easy to describe as a list of IPA symbols, such as `[`p, pʰ, m, t, tʰ, n, k, kʰ, ŋ, s, ...`]`. V, of course, represents a list of vowels, such as `[`a, o, i, u, y, ...`]`. M represents a restricted class of glides, called *medial* in classical Chinese linguistics, pointing to sounds like `[`j, w, ...`]`. The symbol N represents *nasal consonants* in Sun's desription, thus pointing to the three elements `[`m, n, ŋ`]`. \n",
    "\n",
    "The problem with this description is that it is misleading if we try to use it to generate all possible syllables of the Chinese language, because it does not inform us about restrictions which are not licensed by the language. We can easily illustrate this by having a look at possible and impossible words in Standard Chinese:\n",
    "\n",
    "C | M | V | V/N | possible?\n",
    "--- | --- | --- | --- |: ---\n",
    "k | w | a | n | +\n",
    "k | j | a | ŋ | -\n",
    "Ø | j | o | u | +\n",
    "Ø | j | o | a | -\n",
    "n | Ø | a | Ø | +\n",
    "ŋ | Ø | a | Ø | -\n",
    "\n",
    "From the examples, we can see that the problem of the description results not only both the initial specification of the respective class which can appear in a given slot (consider the initial `[`ŋ`]`, which can't appear initially and could just be crossed off the list of initial consonants), but also from the combination of symbols (with `[`k`]` being impossible to combine with `[`j`]`, and `[`a`]` being invalid in coda-position). A satisfying model of the Chinese syllable should be able to create all *possible* sounds of the language, while not producing *impossible* ones. This means chiefly, that we *cannot* rely on simplifying templates when describing the language, as it is usually done in the syllable templates provided by scholars.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all we want is a model that describes all valid syllables of Standard Chinese, without carying for linguistic details or questions, we can easily circumvent this problem by eliciting *all* possible syllables of Chinese. This *is* possible, since the syllable structure of the language is so restricted that we only find about 400 possible syllables and even less than 1600 existing syllables when counting the tones. Even if unsatisfying, such a model would be completely accurate. It would consist of a simple lookup table, and whenever queried, whether a given string is a valid string of Standard Chinese, it would check the input string against the lookup table and return \"true\" if the input string could be found in the lookup table, and \"false\" in the opposite case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disadvantage of such a model would, of course, be that it barely provides us with any new insights about Standard Chinese of phonology in general. Furthermore, if we compare the number of 1600 possible syllables with the observed syllables we find in languages like German, we can find that for a total of 6497 words in German (taken from a subset of the 2002 version of [Kluge's etymological dictionary](:bib:Kluge 2002), for which phonetic transcriptions in [Baayen et al. 1995](:bib:Baayen1995)) were available, is built from as many as 3305 different syllables (see below for the code example). Given that German has no tones, and that we simply counted this number by using LingPy's syllabification procedure, this illustrates that we cannot rely on eliciting all possible cases but should instead think about creating algorithms that infer the phonotactic rules of the languages of the world from empirical data. \n",
    "\n",
    "The following code lines show, how we can compute the number of different syllables in a given dataset. Since LingPy's syllabification function is a bit rough, using only prosody as a proxy, the results need to be taken with care, though, as it is quite likely that we undercount the number of different syllables, since the algorithm artificially breaks valid syllables in German that do not account to the principle of increasing and decreasing sonority around the syllable nucleus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3305 syllables taken from  6497 words in total (2.22 syllables per word).\n"
     ]
    }
   ],
   "source": [
    "from lingpy import *\n",
    "from lingpy.sequence.sound_classes import syllabify\n",
    "rc(morpheme_separator=\"+\")\n",
    "data = [x[2] for x in csv2list('../data/S11-kluge-extracted.tsv', strip_lines=False)[1:] if x[2].strip()]\n",
    "syls = set()\n",
    "syllen = [0]\n",
    "for word in data:\n",
    "    for syl in syllabify(word.split(), output=\"nested\"):\n",
    "        syls.add(' '.join(syl))\n",
    "        syllen[-1] += 1\n",
    "    syllen += [0]\n",
    "print('{0:5} syllables taken from {1:5} words in total ({2:.2f} syllables per word).'.format(\n",
    "    len(syls), len(data), sum(syllen) / len(syllen)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Even if we agree that we should use models that *generate* all possible words of a given language, this does not necessarily mean that we need to rely on the classical idea that a language has a simple sound inventory consisting of sound segments like consonants, vowels, and tones, which the model then concatenates in order to form possible words. The problem of such a naive model is that it ignores the fact that many if not all languages have strong distributional restrictions regarding the positions where certain sounds can appear. The sound `[`ŋ`]`, for example, cannot appear in initial position in German, and the same also holds for Standard Chinese. We can easily address this problem by applying a fuzzy clustering of the sounds of a given language which informs us about these very rough contextual restrictions. We could thus differentiate between possible initial and final consonants. In our example of Standard Chinese, this would mean that `[`ŋ`]` would not appear in the list of initial consonants, but only in the list of final consonants, while `[`n`]` would appear in both lists.  \n",
    "\n",
    "We could even pursue a more radical strategy by treating combinations of initial and medial in SEA languages as a single unit of analysis. This would blow up the number of sounds in our system, but it would help us to go through the pain of inferring context rules for all possible combinations of initial and medial sounds. In fact, we could even argue that syllables like `[`kwan`]` in Chinese could likewise be representad as `[`kw a n `]`, and in an even more radical notion, we could do the same for liquid clusters in German (`[`kr, tr, pr, ...`]`). Inferring rules would become simpler, if we increase the number of sounds in our supposed system of German, although linguists would probably intuitively oppose to this idea.\n",
    "\n",
    "No matter how we model the phonotactics of a given language in the end, we will always have to find the right trade-off between the size of the different symbols we use and the complexity (or number) of rules that we use to combine the symbols to form strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From syllable templates to sequential representations\n",
    "\n",
    "Syllable templates like the one by Sun (2006) mentioned above have the advantage of providing an easy shortcut to approximate the phonology of a language. Their disadvantage is, as we have seen, that they do not really reflect possible and impossible words truthfully. An important aspect that we can employ, however, is the use of specific *sound classes* to indicate in which slots of a syllable which sounds can occur. If we combine a set of possible syllable templates with a set of sound classes (where one and the same sound can potentially be assigned to the same class), we can quite quickly and in a very straightforward manner create a simple model that generates possible words for very different types of languages. \n",
    "\n",
    "The following model, for example, creates languages that remind a bit of the typical tone-less languages of South-East Asia, in which monosyllabic morphemes are the predominant pattern:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 relu\n",
      "    2 krokta\n",
      "    3 ru\n",
      "    4 put\n",
      "    5 nebiŋgok\n",
      "    6 na\n",
      "    7 keletet\n",
      "    8 ki\n",
      "    9 gunpiŋ\n",
      "   10 ro\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "syllables = [\"CV\", \"CVc\", \"CVc\", \"CRVc\", \"RV\", \"NV\"]\n",
    "sounds = {\n",
    "    \"V\": [\"a\", \"i\", \"e\", \"o\", \"u\"],\n",
    "    \"C\": [\"ts\", \"p\", \"t\", \"k\", \"b\", \"d\", \"g\"],\n",
    "    \"R\": [\"l\", \"r\"],\n",
    "    \"N\": [\"m\", \"n\"],\n",
    "    \"c\": [\"p\", \"t\", \"k\", \"r\", \"l\", \"n\", \"m\", \"ŋ\"]\n",
    "}\n",
    "def make_word():\n",
    "    length = random.randint(1,3)\n",
    "    outs = []\n",
    "    for i in range(length):\n",
    "        syl = random.choice(syllables)\n",
    "        out = ''\n",
    "        for elm in syl:\n",
    "            out += random.choice(sounds[elm])\n",
    "        outs += [out]\n",
    "    return ''.join(outs)\n",
    "for i in range(10):\n",
    "    print('{0:5} {1}'.format(i+1, make_word()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disadvantage of such a model, however, is that it has essentially two parts: one that creates the syllable template, and one that fills the template slots with the respective sound classes. The problem of the two-layer structure is that the model creating such a language is:\n",
    "\n",
    "1. difficult to infer (we have to conclude on two unknown structures: the syllable template and the classes for each of the sounds in the language), and \n",
    "2. difficult to evaluate (given a string, it is not easy to say whether it could be produced by our model, since we'll need to write one algorithm that aligns the word to a syllable template and then checks whether sound slots are properly filled).\n",
    "\n",
    "The problem of these models is that they are no longer *sequential*. While simple sequential models can be easily handled with help of a regular grammar that produces string after string based on an underlying network of transition probabilities, our two-layer model has an underlying hierarchy.\n",
    "\n",
    "We can, however, find a very simple way to approximate the two-layered structure as a sequence by representing the 16 sounds no longer as single units, but instead representing them as bigrams, one consisting of their original value (the sound in IPA format), and one consisting of their sound-class value as we defined them in our initial dictionary above. This will create more \"different\" sounds than we had in our hierarchical presentation, but it has the advantage of providing us with a means to handle the process of word generation in a simple transition graph (a Markov model, see part +++ below). We can create this graph directly from our initial model, and all we have to add is a tweak that makes clear the model terminates often enough. But with this sequential representation of our data produced by a hierarchy, we use a few more lines of code, yet we have the advantage of dealing with a model that can be easily understood and applied, and also be learned from the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition graph has 35 nodes\n",
      "    1 koŋ\n",
      "    2 pli\n",
      "    3 te\n",
      "    4 tslum\n",
      "    5 murdra\n",
      "    6 na\n",
      "    7 loletatokriku\n",
      "    8 gi\n",
      "    9 napo\n",
      "   10 nen\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from lingpy.sequence.sound_classes import bigrams\n",
    "\n",
    "TG = nx.DiGraph() # transition graph\n",
    "syllables = [\"CV\", \"CVc\", \"CVc\", \"CRVc\", \"RV\", \"NV\"]\n",
    "sounds = {\n",
    "    \"V\": [\"a\", \"i\", \"e\", \"o\", \"u\"],\n",
    "    \"C\": [\"ts\", \"p\", \"t\", \"k\", \"b\", \"d\", \"g\"],\n",
    "    \"R\": [\"l\", \"r\"],\n",
    "    \"N\": [\"m\", \"n\"],\n",
    "    \"c\": [\"p\", \"t\", \"k\", \"r\", \"l\", \"n\", \"m\", \"ŋ\"]\n",
    "}\n",
    "for syl in syllables:\n",
    "    for elmA, elmB in bigrams(syl):\n",
    "        for soundA in sounds.get(elmA, [elmA]):\n",
    "            for soundB in sounds.get(elmB, [elmB]):\n",
    "                TG.add_edge(soundA+'/'+elmA, soundB+'/'+elmB)\n",
    "            # add start symbols instead of terminal symbol to make sure we can produce longer words as well\n",
    "            if elmB == '$':\n",
    "                for soundC in sounds['R']:\n",
    "                    TG.add_edge(soundA+'/'+elmA, soundC+'/R')\n",
    "                    TG.add_edge(soundA+'/'+elmA, soundC+'/$')\n",
    "                for soundC in sounds['C']:\n",
    "                    TG.add_edge(soundA+'/'+elmA, soundC+'/C')\n",
    "                    TG.add_edge(soundA+'/'+elmA, soundC+'/$')\n",
    "                for soundC in sounds['R']:\n",
    "                    TG.add_edge(soundA+'/'+elmA, soundC+'/R')\n",
    "                    TG.add_edge(soundA+'/'+elmA, soundC+'/$')\n",
    "print('Transition graph has {0} nodes'.format(len(TG)))\n",
    "nx.write_gml(TG, 'transition_graph')\n",
    "\n",
    "def make_word_from_graph():\n",
    "    out = ''\n",
    "    neighbors = list(TG['#/#'])\n",
    "    while True:\n",
    "        next_elm = random.choice(neighbors)\n",
    "        if next_elm[-1] != '$':\n",
    "            out += next_elm.split('/')[0]\n",
    "            neighbors = list(TG[next_elm])\n",
    "        else:\n",
    "            break\n",
    "    return ''.join(out)\n",
    "for i in range(10):\n",
    "    print('{0:5} {1}'.format(i+1, make_word_from_graph()))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see below, the general idea of this sequential representation of an inherently hierarchical model is to increase the size of the alphabet by distinguishing sounds not only with respect to their pure IPA string quality, but also with respect to the context in which they can occur. Contex is hereby broadly defined. In our example above, it refers to the sound symbols that we used in our syllable template, but we can think of many more ways to represent context information as part of the segment of a given sequence. \n",
    "\n",
    "In LingPy, for example, sequences can be represented as tuples of sound classes and prosodic strings. This is the general structure employed by the LexStat algorithm ([List 2014](:bib:List2014d), which we can easily illustrate by loading a file with the LexStat class of LingPy. If LexStat loads a dataset, it automatically adds the information needed to create the different layers of the sequential representation (also called the \"tiers\"). These are, among others: the sound classes (\"CLASSES\"), the prosodic string (\"PROSTRING\"), and the original sequence in tokenized form: \"TOKENS\". The prosodic string itself is derived from a vector representing the sonority of the segments (\"SONARS\"), but also the gaph-weights, which indicate, how easily a given position can be gapped (\"WEIGHTS\").\n",
    "\n",
    "The following code piece contrasts the different pieces of information for the Icelandic counterpart of \"bark (of tree)\" in our small Germanic dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes              P    \tU    \tR    \tK    \tY    \tR    \n",
      "sonars                1.00\t 7.00\t 5.00\t 1.00\t 7.00\t 5.00\n",
      "prostrings           A    \tX    \tM    \tB    \tY    \tN    \n",
      "numbers              5.P.C\t5.U.V\t5.R.c\t5.K.C\t5.Y.V\t5.R.c\n",
      "weights                2.0\t  1.5\t  1.1\t 1.75\t  1.3\t  0.8\n",
      "tokens               b    \tœ    \tr    \tk    \tʏ    \tr    \n"
     ]
    }
   ],
   "source": [
    "lex = LexStat('../data/S10-GER.tsv')\n",
    "for h in ['classes', 'sonars', 'prostrings', 'numbers', 'weights', 'tokens']:\n",
    "    print('{0:20}'.format(h), '\\t'.join(['{0:5}'.format(x) if not str(x).isdigit() else '{0:5.2f}'.format(x) for x in lex[19, h]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Enhanced modeling of sound sequences with help of multi-tiered sequence models\n",
    "\n",
    "We can easily expand on the idea of representing more than just the sound segments when representing a word from in linguistics, if we only accept the idea of \n",
    "\n",
    "1. taking the sound segments as the smallest (atomic) unit of representation, and\n",
    "2. forcing all values for all levels to be aligned with the smallest representation (while accepting to repeat information if needed).\n",
    "\n",
    "Let us consider a very simple example for such a *multi-tiered sequence representation*, by parsing the word Bulgarian *jabəlka* \"apple\" with different representations provided by LingPy. We start with the classical representations of sound classes (using simple \"consonant-vowel\" models), but we further expand our model by checking not only the sound class of a given sound, but also which sound class follows or precedes a given sound:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens     j\ta\tb\tə\tl\tk\ta\n",
      "cv-plain   C\tV\tC\tV\tC\tC\tV\n",
      "context-l  #\tC\tV\tC\tV\tC\tC\n",
      "context-r  V\tC\tV\tC\tC\tV\t$\n",
      "bigrams-l  ##\t#C\tCV\tVC\tCV\tVC\tCC\n",
      "bigrams-r  VC\tCV\tVC\tCC\tCV\tV$\t$$\n"
     ]
    }
   ],
   "source": [
    "seq = \"j a b ə l k a\".split()\n",
    "cv = tokens2class(seq, model='cv')\n",
    "bigs = bigrams(cv)\n",
    "print('tokens    ', '\\t'.join(seq))\n",
    "print('cv-plain  ', '\\t'.join(cv))\n",
    "print('context-l ', '\\t'.join(['#']+cv[:-1]))\n",
    "print('context-r ', '\\t'.join(cv[1:]+['$']))\n",
    "print('bigrams-l ', '\\t'.join(['##']+['{0}{1}'.format(x, y) for x, y in bigs[:-2]]))\n",
    "print('bigrams-r ', '\\t'.join(['{0}{1}'.format(x, y) for x, y in bigs[2:]+['$$']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What these structures provide is a pool of different possibly important contexts for either word generation or rule inference. We can easily adjust the contexts, by adding additional information that goes beyond what follows left and right of a given segment. For example, when dealing with tonal sequences, we can just assign the tone to each sound segment and no longer annotate the tone as a separate unit:\n",
    "\n",
    "form | in. | nuc. | fin. \n",
    "--- | --- | --- | --- \n",
    "piŋ⁵⁵ | p / ⁵⁵ | i / ⁵⁵ | ŋ / ⁵⁵ \n",
    "pin³⁵ | p / ³⁵ | i / ³⁵ | n / ³⁵\n",
    "\n",
    "While this may seem strange at first sight, it makes a lot of sense, also as a heuristic procedure, since we know well that tone may often correlate with voicing and devoicing in the history of the Chinese dialects. If we model Middle Chinese source forms as multi-tiers in which the tone information is given as part of the information on the initial, we can immediately see that the Middle Chinese \"flat\" tone (*píng*, P) leads to a different reflex in some dialects than the three other tones (*shǎng*, *qù*, *rù*, SQR), as shown in the following figure (List under review):\n",
    "\n",
    "![img](s11-fig1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this essentially shows is that we can use the idea of using multi-layered, multi-tiered sequence representations to generate a pool of potential hypotheses from which we can then algorithmically or manually pick those that account for a given output. Multi-tiered sequence representation is thus, as we will see in the following section, a way to generate hypotheses to derive or induce rules, addressing our task 2, mentione"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
