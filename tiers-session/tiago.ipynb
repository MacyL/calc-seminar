{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On tier representation\n",
    "\n",
    "As in biology, linguistic data and relationships are commonly represented and visualized with one of three fundamental structures: the sequence, for sequential data, the tree, for hierarchical non-sequential data, and the network, for non-hierachical non-sequential data. Typical examples are n-grams, syntax tree, and colexification networks.\n",
    "\n",
    "![ngrams](ngrams.jpg)\n",
    "\n",
    "Ngrams\n",
    "\n",
    "![syntax tree](syntaxtree.jpg)\n",
    "\n",
    "Syntax Tree\n",
    "\n",
    "![colex](colex.jpg)\n",
    "\n",
    "Colexification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequential representation is by far the most common one for representing sound sequences, both for easiness of using it, for the example of alphabets, and for the fact that, even though suprasegmental features might be at play, sound sequences are themselves sequential and temporally delimited. As such, most mathematical models for representing sequences of speech sounds are some kind of sequence (defined as an \"enumerated collection of objects in which repetitions are allowed and with no overlapping between the members\"), with member as samples from a random distribution. It is important to remember that, in this mathematical sense, \"random\" does not necessarily means \"without a specific pattern\" or \"unpredictable\" (as the sequence of sounds is usually quite predictable, for example due to language inventory and phonotactics), but just that the sequence is composed of different elements that follow a probability distribution.\n",
    "\n",
    "The most common way of modelling such sequentes is with a Markov model. While there are many different structures and approaches that qualify as \"Markovian\" (such as Markov chains, Hidden Markov Models, etc.), we can simply think of a Markov model simply as a model describing a sequence of possible events (the \"elements\") in which the probability of each event depends only on the state attained in the previous event. For this reason, Markov models are \"memoryless\", in the sense that nothing informs the transition between states with the exception of the current one and, more important, that the probability for a transition is the same no matter its position in the sequence and the number of previous transitions; however, it is necessary to remember that the current state is not necessarily composed of a single element, as we can, for example, model a language using bigrams and trigrams (that is, preceding sequences of two or three characters that inform on the probability of the next character).\n",
    "\n",
    "For a more concrete example of Markov models, in English, if we have no other information about the context of occurence, after a sound /ð/ (represented in writing by \"TH\") we are right to expect the sound /iː/ (\"E\") as the most probable, given that the article \"THE\" is the most common word in the language and that the /ðiː/ sequence has a high overall frequency. We can, in fact, easily train a model on such premises. If we consider a context composed only of one sound (a \"monogram\", even though, as we just mentioned, larger, combined, and other alternatives are possible), we can easily come up with a matrix of probabilities of transition from state to state (i.e., from sound to sound) such as the following one by counting the number of observations of a sound S1 followed by a sound S2.\n",
    "\n",
    "| S1 \\ S2    | aɪ | aʊ    | b    | d    | dʒ   | (...) |ʒ    | θ |\n",
    "|-----|----|-------|------|------|------|-------|------|---|\n",
    "| aɪ | 0.03 | 0.04 | 2.53 | 9.18 | 0.55 |-------| 0.00 | 0.10 |\n",
    "| aʊ | 0.03 | 0.00 | 2.01 | 4.68 | 0.25 |-------| 0.00 | 2.20 |\n",
    "| b | 2.24 | 1.20 | 0.00 | 0.51 | 0.15 |-------| 0.00 | 0.01 |\n",
    "| d | 2.50 | 1.09 | 0.79 | 0.02 | 0.02 |-------| 0.00 | 0.05 |\n",
    "| dʒ | 1.18 | 0.14 | 0.04 | 2.49 | 0.00 |-------| 0.00 | 0.00 |\n",
    "| (...) |\n",
    "| ʒ | 0.55 | 1.11 | 0.00 | 2.21 | 0.00 |-------| 0.00 | 0.00 |\n",
    "| θ | 1.77 | 0.71 | 1.15 | 0.62 | 0.09 |-------| 0.00 | 0.00 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a model such as this is reasonably effective given its simplicity, it fails to support more advanced modelings such as those described above. In terms of patterns of sounds, for example, while the probability distributions it encapsulates could be used as a first step for generalizing observations, there are limits in terms of context and not much can be done without a human intervention in each single stage. In terms of phonetic representation, it cannot fully account for suprasegmental features such as tones (i.e., the contrastive elements that cannot be analyzed as distinct segments, but which belong to a subgroup of them, non necessarily contiguous, as in the case of vowel harmony, and not even necessarily following the same segment boundaries). Expanding the context and the number of observations to capture suprasegmental features ends up modelling each combination of features on their own, losing any generalization; in fact, for other usages such as pseudo-word generation, not only the context is too limited to capture complex patterns as well as medium- and long-distance relationships, it is also unable to encode information that is external to the sum of individual elements (for example, if the pseudo-word is supposed to be a verb or a noun). \n",
    "\n",
    "Some of these problems can be solved or partially remediated with more complex approaches, such as higher order n-grams (i.e., more context) or combined information, but we cannot surpass the limit that each element can only encode one item of information and that our system might be more than the sum of its elements and their relationships. This is particularly valid in linguistic research, where many of the possibilities and hypotheses are weighted in terms of typological knowledge that is not encoded in what is being observed.\n",
    "\n",
    "One possible objection to this is that information such as IPA graphemes is by no way atomic: even without considering possible suprasegmental information or more context, a graphame such as /b/ already carries many levels, or \"tiers\", of information, such as its manner of articulation (\"stop\"), its place of articulation (\"bilabial\"), its voiceness (\"voiced\"), and so on, including \"negative information\" such as the impossibility of it being a syllable nucleus (in most languages). Additional information can be obtained from the word where the sound is realized, such as the stress of its syllable, and even from the system where it is produced, such as the frequency of the word under analysis, its age, the donor language in case of borrowings, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our proposed solution is to consider parallel, multilayered and conceptually linked sequences, which are partly analogous to some solutions with marginal adoption in stochastic methods such as Layered Hidden Markov models. In our proposal, a number of \"tiers\" (levels) can be expressed in its relationship to a given sequence (i.e., word). While the most obvious ones are distinctive features, suprasegmental information and extra lexical information, such as we just described, this can potentially accomodate even the relationship between two or more words, such as cognates. One reduced example is presented here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tier             | Description            | Alignment           |\n",
    "|------------------|------------------------|---------------------|\n",
    "| SOURCE           | source sounds          | s | w | e  | r | d  |\n",
    "| CV  ?X           | previous sound C or V  | ∅ | C | C  | V | C  |\n",
    "| CV  X?           | following sound C or V | C | C | C  | C | ∅  |\n",
    "| SOUND CLASS  ?X  | previous sound class   | ∅ | S | W  | V | R  |\n",
    "| SOUND CLASS  X?  | following sound class  | W | V | R  | T | ∅  |\n",
    "| STRESS           | stress in source       | 1 | 1 | 1  | 1 | 1  |\n",
    "| TARGET           | target sounds          | ʃ | v | e: | r | t  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a huge amount of tiers is not feasible for human inspection and manipulation, tiers can be easily pre-processed by algorithms for finding relationships that would take many hours of work of manual inspection; in particular, automatic methods should be able to easily deal and remove the many layers of information that are either strongly correlated or plain redudant (for example, the fact that all vowels are voiced). One preliminary example of this is shown below, where we build an aligned dataset of reconstructed Proto-Germanic and German words and test, with a decision tree, for the features that are significant in terms of prediction of the initial sound in a German word given the initial sound in the corresponding Proto-Germanic word. In this toy example, we are considering all features from \"source\" (Proto-Germanic) but only two features, \"stop\" and \"voiced\", from \"target\" (German).\n",
    "\n",
    "![dt](dt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is a toy example with only 101 observations and a single tree (we should really run it multiple times, having a \"forest\" that allows us to balance the results of each tree), it is still able to capture some of the advantages of a multitier system. In particular, the algorithm identified \"alveolar\" as the most informative tier in terms of relationship between the \"source\" (Proto-Germanic) and the \"target\" (German) tier. The very first decision is based on the initial phoneme in Proto-Germanic not being an alveolar, which when true (left branch) leads to a population where all sounds are stops (70 stop vs. 0 non-stops), as our dataset only has alveolar fricatives; among the stops, the only decision we need to predict the target is whether the source sound is voiced or not, with 13 voiceless plosives and 57 voiced ones. \n",
    "\n",
    "The decision tree captured the most common correspondences in terms of manner of articulation and voiceness between initials in Proto-Germanic and German:\n",
    "\n",
    "* voiced non-alveolars were kept as such (first leaf, e.g., boːk/buːk)\n",
    "\n",
    "| Tier           | #1 | #2 | #3 |\n",
    "|----------------|----|----|----|\n",
    "| Proto-Germanic |  b | oː |  k |\n",
    "| alveolar       |  0 |  0 |  0 |\n",
    "| voiced         |  1 | 1  |  0 |\n",
    "| front +2       |  0 |  0 |  0 |\n",
    "| German         |  b | uː |  x |\n",
    "\n",
    "\n",
    "* voiceless non-alveolars became voiced, usually with a change in manner of articulation which is not considered here (second leaf, e.g. θuːrst/dʊrst)\n",
    "\n",
    "| Tier           | #1 | #2 | #3 | #4 | #5 |\n",
    "|----------------|----|----|----|----|----|\n",
    "| Proto-Germanic |  θ | uː |  r |  s |  t |\n",
    "| alveolar       | 0  | 0  |  1 | 1  | 1  |\n",
    "| voiced         | 0  | 1  | 1  | 0  | 0  |\n",
    "| front +2       | 0  | 0  | 0  | 0  | 0  |\n",
    "| German         |  d |  ʊ |  r |  s |  t |\n",
    "\n",
    "\n",
    "* voiced alveolars were kept as such (third leaf, e.g., liːna/lainə)\n",
    "\n",
    "| Tier           | #1 | #2 | #3 | #4 |\n",
    "|----------------|----|----|----|----|\n",
    "| Proto-Germanic |  l | iː |  n |  a |\n",
    "| alveolar       | 1  | 0  |  0 | 0  |\n",
    "| voiced         | 1  | 1  | 1  | 1  |\n",
    "| front +2       | 0  | 0  | 0  | 0  |\n",
    "| German         |  l |  ai |  n |  ə |\n",
    "\n",
    "\n",
    "* voiceless alveolars where kept as such, but usually with a change in manner of articulation, if the third sound was a vowel (fourth leaf, e.g., swesteːr/ʃvɛstər)\n",
    "\n",
    "| Tier           | #1 | #2 | #3 | #4 | #5 | #6 | #7 |\n",
    "|----------------|----|----|----|----|----|----|----|\n",
    "| Proto-Germanic |  s | w  |  e |  s |  t | eː | r  |\n",
    "| alveolar       | 1  | 0  |  0 | 1  | 0  | 0  |  1 |\n",
    "| voiced         | 0  | 1  | 1  | 0  | 0  | 1  |  1 |\n",
    "| front +2       | 1  | 0  | 0  | 1  | 0  | 0  | 0  |\n",
    "| German         |  ʃ |  v |  ɛ |  s |  t | ə  | r  |\n",
    "\n",
    "* voiceless alveolars became voiced if the following sound is a vowel (fifth leaf, e.g., setjan/zɪtsən).\n",
    "\n",
    "| Tier           | #1 | #2 | #3  | #4 | #5 | #6 |\n",
    "|----------------|----|----|-----|----|----|----|\n",
    "| Proto-Germanic |  s | e  |  t  |  j |  a |  n |\n",
    "| alveolar       | 1  | 0  |  0  | 0  | 0  | 0  |\n",
    "| voiced         | 0  | 1  | 0   | 1  | 1  | 1  | \n",
    "| front +2       | 0  | 0  | 0   | 0  | 0  | 0  |\n",
    "| German         |  z |  ɪ |  ts | - |  ə | n  |\n",
    "\n",
    "\n",
    "While reading and interpreting the results of a decision tree is not easy, and even harder when random forests are involved, these results are a good demonstration of how such system would work and how it is able to capture patterns of correspondence given a set of examples. It is also theoretically possible to map such decisions to a standard A > B / C notation as used in historical linguistics.\n",
    "\n",
    "A couple of notes before ending. First, in terms of having to generate a single tree. While the first decision was based in feature \"alveolar\", due to the fact of all initial fricatives in our dataset being alveolar, most linguists would probably opt for the statistically equal rule based on feature \"manner\", as, without any additional information, sound correspondences are more likely to be related to manner than place of articulation. Multiple runs of the algorithm (\"the random forest\") would probably capture both rules (manner and place of articulation) with the same probability, which is a good indication that, given *exclusively* the encoded information, they are equally informative. The preference for manner of articulation is an expert bias, not necessarily false, that should either be accounted as such or encoded with enough information so that the algorithm is able to capture it.\n",
    "\n",
    "A second note is in terms of tree pruning, i.e., reducing the size of the model. While we are presenting the entire tree, from the population of the fourth and last level (the right-most decision, at the bottom), we can see that an entire rule is estipulated to account for a single case of voiced stop. Rules such as this allow to quickly eyeball potential errors and outliers in our dataset (such as typos or borrowings), but we can also estipulate a cutoff in terms of decision depth, so as to capture the most informative rules (i.e., the ones that explain most of the observed data).\n",
    "\n",
    "A final reminder is that we are not forced to compare only \"source\" and \"target\", and, in fact, the system allows us to compare any group of tiers, including multiple words. For example, we could encode other Germanic languages and try to capture unexplained transitions in one language by tier observed in a sister language, thus considering information that is lost in the first one but can be accounted for by its cognates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
