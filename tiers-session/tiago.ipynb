{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On tier representation\n",
    "\n",
    "As with biology, linguistic data and relationships are commonly represented and visualized with one of three fundamental structures: the sequence, for sequential data, the tree, for hierarchical non-sequential data, and the network, for non-hierachical non-sequential data. Typical examples are n-grams, syntax tree, and colexification networks.\n",
    "\n",
    "![ngrams](ngrams.jpg)\n",
    "\n",
    "Ngrams\n",
    "\n",
    "![syntax tree](syntaxtree.jpg)\n",
    "\n",
    "Syntax Tree\n",
    "\n",
    "![colex](colex.jpg)\n",
    "\n",
    "Colexification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequential representation is by far the most common one for representing sound sequences, both for easiness of using it, for the example of alphabets, and for the fact that sound sequences are themselves sequential and temporally delimited. As such, most mathematical model of utterances represent words as sequences of elements from a random distribution. It is important to remember that, in this sense, \"random\" does not necessarily means \"without a specific pattern\" or \"unpredictable\" (as the sequence of sounds is usually quite predictable due to the language inventory and to the phonotactics), but just that the sequence is composed of different elements.\n",
    "\n",
    "The most common way of modelling such sequentes is with a Markov model. While there are many different structures and approaches that qualify as \"Markovian\" (such as Markov chains, Hidden Markov Models, etc.), we can simply think of a Markov model simply as a model describing a sequence of possible events (the \"elements\") in which the probability of each event depends only on the state attained in the previous event. For example, in English, if we have no other information about the context of occurence, after a sound /ð/ (represented in writing by \"TH\") we are right to expect the sound /iː/ (\"E\") as the most probable, as the article \"THE\" is the most common word in the language.\n",
    "\n",
    "We can, in fact, easily train a model on such premises. If we consider a context composed only of one sound (a \"monogram\", even though larger, combined, and other alternatives are possible), we can easily come up with a matrix of probabilities of transition from state to state (i.e., from sound to sound) such as the following:\n",
    "\n",
    "|     | aɪ | aʊ    | b    | d    | dʒ   | (...) |ʒ    | θ |\n",
    "|-----|----|-------|------|------|------|-------|------|---|\n",
    "| aɪ | 0.03 | 0.04 | 2.53 | 9.18 | 0.55 |-------| 0.00 | 0.10 |\n",
    "| aʊ | 0.03 | 0.00 | 2.01 | 4.68 | 0.25 |-------| 0.00 | 2.20 |\n",
    "| b | 2.24 | 1.20 | 0.00 | 0.51 | 0.15 |-------| 0.00 | 0.01 |\n",
    "| d | 2.50 | 1.09 | 0.79 | 0.02 | 0.02 |-------| 0.00 | 0.05 |\n",
    "| dʒ | 1.18 | 0.14 | 0.04 | 2.49 | 0.00 |-------| 0.00 | 0.00 |\n",
    "| (...) |\n",
    "| ʒ | 0.55 | 1.11 | 0.00 | 2.21 | 0.00 |-------| 0.00 | 0.00 |\n",
    "| θ | 1.77 | 0.71 | 1.15 | 0.62 | 0.09 |-------| 0.00 | 0.00 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a model such as this is reasonably effective given its simplicity, it fails to support more advanced modelings such as those described above. In terms of patterns of sounds, for example, while the probability distributions it involves could be used as a first step for generalizing observations, there are limits in terms of context and not much can be done without a human intervention in each single stage. In terms of phonetic representation, it cannot fully account for suprasegmental features such as tones, i.e., the contrastive elements that cannot be analyzed as distinct segments but belong to a subgroup of them (sometimes not even following the boundaries of the segments themselves). For pseudo-word generation, not only the context is too limited to capture complex pattern and medium- and long-distance relationships, it also cannot encode information that is above the level of the individual elements, such as if the pseudo-word being generated is a verb or a noun.\n",
    "\n",
    "While some of the problems can be solved or partially remediated with more complex approaches, such as higher order n-grams (i.e., more context), or combined information, we cannot surpass the limit that each element can only encode one item of information.\n",
    "\n",
    "One possible objection to this is that information such as IPA graphemes is by no way atomic: even without considering possible suprasegmental information or more context, a graphame such as /b/ already carries many levels, or \"tiers\", of information, such as its manner of articulation (\"occlusive\"), its place of articulation (\"bilabial\"), its voiceness (\"voiced\"), and so on. In actual words, more information can be obtained by inspection of the word where it is pronuounced, such as the stress of its syllable and its intonation, and even the system where it is pronounced, such as the frequency of such word, its age, the donor language in case of borrowings, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our proposed solution is to consider parallel, multilayered and conceptually linked sequences, which are to a point analogous to some solutions with marginal adoption in stochastic methods such as Layered Hidden Markov models. In our proposal, a number, potentially enormous, of tiers can be expressed in its relationship to a given sequence (i.e., word). While the most obvious ones are distinctive features, suprasegmental information and extra lexical information, such as we just described, this can potentially accomodate even the relationship between two or more words, such as cognates. One reduced example is presented here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tier             | Description            | Alignment           |\n",
    "|------------------|------------------------|---------------------|\n",
    "| SOURCE           | source sounds          | s | w | e  | r | d  |\n",
    "| CV  ?X           | previous sound C or V  | ∅ | C | C  | V | C  |\n",
    "| CV  X?           | following sound C or V | C | C | C  | C | ∅  |\n",
    "| SOUND CLASS  ?X  | previous sound class   | ∅ | S | W  | V | R  |\n",
    "| SOUND CLASS  X?  | following sound class  | W | V | R  | T | ∅  |\n",
    "| STRESS           | stress in source       | 1 | 1 | 1  | 1 | 1  |\n",
    "| TARGET           | target sounds          | ʃ | v | e: | r | t  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a huge amount of tiers is not feasible for human inspection and manipulation, tiers can be easily pre-processed by algorithms for finding relationships that would take many hours of work of manual inspection; in particular, automatic methods should be able to easily deal and remove the many layers of information that are either strongly correlated or plain redudant (for example, that a vowel is voiced). One preliminary example of this is shown below, where we build an aligned dataset of reconstructed Proto-Germanic and German words and test, with a decision tree, for the features that are significant in terms of prediction of the initial sound in German given the initial sound in Proto-Germanic. In this toy example, we are considering all features from \"source\" (Proto-Germanic) but only two features, \"stop\" and \"voiced\", from \"target\" (German).\n",
    "\n",
    "![dt](dt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is a toy example with only 101 cases and a single tree (we should really run it multiple times, having a \"forest\" that allows us to balance the results of each tree), it is still able to capture some of the advantages of a multitier system. In particular, the algorithm identified \"alveolar\" as the most informative tier in terms of relationship between the \"source\" (Proto-Germanic) and the \"target\" (German) tier. The very first decision is based on the initial phoneme in Proto-Germanic not being an alveolar, which when true (left branch) leads to the obvious population when all sounds are stops (70 stop vs. 0 non-stops), as our dataset only has alveolar fricatives; among the stops, the only decision we need to predict the target is whether the source sound is voiced or not, with 13 voiceless plosives and 57 voiced ones. \n",
    "\n",
    "In short, the decision tree captured the most common correspondences in terms of manner of articulation and voiceness between initials in Proto-Germanic and German:\n",
    "\n",
    "* voiced non-alveolars were kept as such (first leaf, e.g., boːk/buːk)\n",
    "\n",
    "| Tier           | #1 | #2 | #3 |\n",
    "|----------------|----|----|----|\n",
    "| Proto-Germanic |  b | oː |  k |\n",
    "| alveolar       |  0 |  0 |  0 |\n",
    "| voiced         |  1 | 1  |  0 |\n",
    "| front +2       |  0 |  0 |  0 |\n",
    "| German         |  b | uː |  x |\n",
    "\n",
    "\n",
    "* voiceless non-alveolars became voiced, usually with a change in manner of articulation (second leaf, even though we were not considering manner of articulation here)\n",
    "\n",
    "| Tier           | #1 | #2 | #3 | #4 | #5 |\n",
    "|----------------|----|----|----|----|----|\n",
    "| Proto-Germanic |  θ | uː |  r |  s |  t |\n",
    "| alveolar       | 0  | 0  |  1 | 1  | 1  |\n",
    "| voiced         | 0  | 1  | 1  | 0  | 0  |\n",
    "| front +2       | 0  | 0  | 0  | 0  | 0  |\n",
    "| German         |  d |  ʊ |  r |  s |  t |\n",
    "\n",
    "\n",
    "* voiced alveolars were kept as such (third leaf)\n",
    "\n",
    "| Tier           | #1 | #2 | #3 | #4 |\n",
    "|----------------|----|----|----|----|\n",
    "| Proto-Germanic |  l | iː |  n |  a |\n",
    "| alveolar       | 1  | 0  |  0 | 0  |\n",
    "| voiced         | 1  | 1  | 1  | 1  |\n",
    "| front +2       | 0  | 0  | 0  | 0  |\n",
    "| German         |  l |  ai |  n |  ə |\n",
    "\n",
    "\n",
    "* voiceless alveolars where kept as such, but usually with a change in manner of articulation, if the third sound was a vowel (fourth leaf)\n",
    "\n",
    "| Tier           | #1 | #2 | #3 | #4 | #5 | #6 | #7 |\n",
    "|----------------|----|----|----|----|----|----|----|\n",
    "| Proto-Germanic |  s | w  |  e |  s |  t | eː | r  |\n",
    "| alveolar       | 1  | 0  |  0 | 1  | 0  | 0  |  1 |\n",
    "| voiced         | 0  | 1  | 1  | 0  | 0  | 1  |  1 |\n",
    "| front +2       | 1  | 0  | 0  | 1  | 0  | 0  | 0  |\n",
    "| German         |  ʃ |  v |  ɛ |  s |  t | ə  | r  |\n",
    "\n",
    "* voiceless alveolars became voiced if the following sound is a vowel (fifth leaf).\n",
    "\n",
    "| Tier           | #1 | #2 | #3  | #4 | #5 | #6 |\n",
    "|----------------|----|----|-----|----|----|----|\n",
    "| Proto-Germanic |  s | e  |  t  |  j |  a |  n |\n",
    "| alveolar       | 1  | 0  |  0  | 0  | 0  | 0  |\n",
    "| voiced         | 0  | 1  | 0   | 1  | 1  | 1  | \n",
    "| front +2       | 0  | 0  | 0   | 0  | 0  | 0  |\n",
    "| German         |  z |  ɪ |  ts | - |  ə | n  |\n",
    "\n",
    "\n",
    "While reading and interpreting the results of a decision tree is not easy, something even harder in terms of random forests, these results are a good demonstration of how such system would work and how it is able to capture patterns of correspondence given a set of examples. It is also theoretically possible to map such decisions to a standard A > B / C notation as used in historical linguistics.\n",
    "\n",
    "A couple of notes is valid in this case. The first is, once more, in terms of having to generate a single tree. While the first decision was based in feature \"alveolar\", due to the fact of all initial fricatives in our dataset being alveolar, most linguists would probably opt for the statistically equal rule based on feature \"manner\", as, without any additional information, sound correspondences are more likely to be related to manner than place of articulation. Multiple runs of the algorithm (\"the random forest\") would probably capture both rules (manner and place of articulation) with the same probability, which is a good indication that, given *exclusively* the encoded information, they are equally informative. The preference for manner of articulation is a human bias, which is not necessarily false, that either be accounted as such or encoded with enough information so that the algorithm would capture this.\n",
    "\n",
    "A second note is in terms of the cutoff. While we are presenting the entire tree, from the population of the fourth and last level (the right-most decision, at the bottom), we can see that an entire rule (if \"front +2\" is true, i.e., if the phoneme two positions after the initial, thus the third phoneme, is a front vowel) is estipulate to account for a single case of voiced stop. Rules such as this are not informative in case of single observations (the word in question is XXXXXX -- TIAGO: will check), but they can be capture by multiple runs (again, the random forest). Even more important, they allow to quickly eyeball potential errors and outliers in our dataset (such as typos or borrowings), and we can stipulate a cutoff in terms of number of decision so as to capture the most informative rules, the ones that explain most of the observed data.\n",
    "\n",
    "A final reminder is that in this system we would not be forced to compare only \"source\" and \"target\", allowing any group of tiers (including multiple words). For example, we could encode other Germanic languages and try to capture unexplained transitions in one language by tier observed in a sister language, thus considering information that is lost in the first one but can be accounted for by cognates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show the results of a Random Forest algorithm, telling us exactly which features are more significat and the weight of each of them in the prediction. In the case of the algorithm above, a toy random forest computation (which admitedly should have been run more times for more consistent results), returns the scores reported below. The results indicate that the most informative feature is \"bilabial\", followed by \"voiceless\" and \"velar\". This suggest that, in most cases, the initial sound in the \"target\" tier of our toy dataset can be predicted by the consonant values of the initial sound of the \"source\" tier alone (remember that here we are not considering what rules of change might be involved, only what are the most informative tiers in terms of rules of change); this is also enough to suggest that the type of the initial sound alone, consonant or vowel, is not as informative the position of voiceness in terms of relationship between the \"source\" and \"target\" tiers (and, in fact, the tier \"TYPE\" doesn't even show among the most informative tiers below, as it is implied by the others -- if a sound is \"bilabial\", in all cases it will also be a consonant). Other informative features are \"close +1\", indicating if the following vowel is closed (\"high\") or not, and \"nasal +1\", indicating if the second sound has a lowered vellum.\n",
    "\n",
    "| Tier                | Score  |\n",
    "|---------------------|--------|\n",
    "| bilabial            | 0.1455 |\n",
    "| voiceless           | 0.0929 |\n",
    "| velar               | 0.0878 |\n",
    "| close +1            | 0.0795 |\n",
    "| nasal +1            | 0.0777 |\n",
    "| rounded +1          | 0.0609 |\n",
    "| unrounded +2        | 0.0483 |\n",
    "| TYPE +1             | 0.0463 |\n",
    "| TYPE +2             | 0.0396 |\n",
    "| near-back +1        | 0.0361 |\n",
    "| to-mid-low +2       | 0.0359 |\n",
    "| fricative +2        | 0.0311 |\n",
    "| epiglottal +2       | 0.0305 |\n",
    "| labialized-velar +1 | 0.0297 |\n",
    "| nasal +2            | 0.0276 |\n",
    "| voiceless +2        | 0.0257 |\n",
    "| close-mid +1        | 0.0242 |\n",
    "| labial +1           | 0.0241 |\n",
    "| post-alveolar +1    | 0.0222 |\n",
    "| mid +2              | 0.0174 |\n",
    "| to-mid +2           | 0.0070 |\n",
    "| central +1          | 0.0041 |\n",
    "| labial +2           | 0.0028 |\n",
    "| open-mid +2         | 0.0019 |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
